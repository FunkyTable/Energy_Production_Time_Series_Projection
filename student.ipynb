{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Achieving the Paris Agreement Goals: Projecting Energy Production Sources in the United States With Time Series Modeling \n",
    "\n",
    "* Student name: Greg Osborne\n",
    "* Student pace: self paced / part time\n",
    "* Scheduled project review date/time: 4/28/23, 2:45 PM\n",
    "* Instructor name: Morgan Jones\n",
    "* Blog post URL: https://medium.com/@gregosborne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Understanding\n",
    "## Stakeholder: [Environmental Protection Agency (EPA)](https://www.epa.gov/)\n",
    "\n",
    "## Overview\n",
    "The United States needs to achieve Paris Agreement greenhouse gas reduction goals in the energy production sector by 2050. The nation must understand current trends in the sector to see if EPA intervention is required to meet the targets. This project projects current energy production trends in the United States and recommends changes to achieve the Paris Agreement reduction goals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background: \n",
    "On December 12, 2015, the historic [Paris Agreement](https://apnews.com/article/climate-climate-change-john-kerry-paris-archive-81dabae32cb8463b86bd85d762da9e6d) legally bound the United States and other nations of the world to limit global warming to well below 2 °C (3.6 °F) over preindustrial levels. \n",
    "\n",
    "The Paris Agreement also commissioned the Intergovernmental Panl no Climate Change ([IPCC](https://www.ipcc.ch/)) to review the effects of climate change at 1.5 °C (2.7 °F). [The IPCC released its report on the matter in 2018](https://www.ipcc.ch/sr15/chapter/spm/), detailing the pestilence of a warmer world. \n",
    "\n",
    "To limit climate change to no greater than 1.5 °C over pre-industrial levels, the IPCC's 2018 special report concluded that greenhouse gas (GHG) emissions must [\"decline by about 45% from 2010 levels by 2030 (40–60% interquartile range), reaching net zero around 2050.\"](https://www.ipcc.ch/sr15/chapter/spm/#article-spm-c) Today, in 2023, we are [already at 1.1 °C (2 °F)](https://earthobservatory.nasa.gov/world-of-change/global-temperatures). With GHG emissions as they are, scientists anticipate this average to grow by about 0.2 °C per decade unless GHG emissions are cut."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buisness Problem: \n",
    "\n",
    "The United States needs to ensure our energy production sector achieves the Paris Agreement goals. \n",
    "\n",
    "GHG emissions occur in multiple sectors of the economy. Electricity generation releases [about 25% of GHG emissions in the United States](https://www.epa.gov/ghgemissions/sources-greenhouse-gas-emissions), [and about 40% globally](https://www.iea.org/data-and-statistics/charts/global-energy-related-co2-emissions-by-sector). The EPA commissioned Greg Osborne to project current energy production trends and recommend policies to help the United States reach the GHG reduction targets set by the IPCC. \n",
    "\n",
    "Electricity generation refers to power plants creating electricity to distribute across power lines to residential and business locations. Electricity sources include fossil fuel methods, burning coal, oil and natural gas which emit GHG, and sources that do not emit GHG, nuclear, wind turbines, solar panels and hydroelectrical. Reducing America's GHG emissions and exporting that technology to our allies will result in greater reduction of GHG emissions than any other sector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-Series Modeling\n",
    "\n",
    "The time series analysis requires projecting two factors into the future:\n",
    "\n",
    "   **1. Construction/Reduction Rate of GHG-Emitting Power Generation**\n",
    "\n",
    "Unfortunately, not only are fossil fuels still powering our lifestyles, but power companies in the US still [plan to open natural gas power plants in future](https://www.eia.gov/todayinenergy/detail.php?id=50436). Construction of new coal plants has [stalled in the United States](https://www.scientificamerican.com/article/will-the-u-s-ever-build-another-big-coal-plant/), but worldwide, several coal-fired power plants are scheduled to be [built in the future](https://www.reuters.com/business/energy/cop26-aims-banish-coal-asia-is-building-hundreds-power-plants-burn-it-2021-10-29/). The time series analysis must consider the growth and reduction of fossil-fuel power plants.\n",
    "\n",
    "   **2. Construction Rate of Clean Power Generation**\n",
    "\n",
    "Contrary to what the crisis needs, we cannot build a billion wind turbines overnight. We can only build clean energy sources as materials, labor availability, construction time, and politics allow. Fortunately, construction of new renewable and nuclear power production is underway. The time series analysis will model current trends of construction to see if they can meet the The United State's electricity needs as fossil fuels diminish.\n",
    "\n",
    "I will then compare this time series analysis with two other factors that are not projected with a time series model:\n",
    "\n",
    "   **1. Increase in Electricity Demand**\n",
    "\n",
    "America's demand for electricity will rise as we cut emissions across all sectors. The poster-child example of this is the impending fuel source change for automobiles. Car manufacturers representing a quarter of global sales have pledged to [cease production of internal-combustion-engine cars](https://www.caranddriver.com/news/a38213848/automakers-pledge-end-gas-sales-2040/) within the IPCC's timeline. The most likely power source for their new cars is electricity, creating greater demand. The data used to estimate the increase in Electricity demand is provided by the International Energy Agency.\n",
    "\n",
    "   **2. The Paris Agreement GHG Emissions reduction targets**\n",
    "\n",
    "As part of the Paris Agreement, the IPCC has determined that GHG emissions must [\"decline by about 45% from 2010 levels by 2030 (40–60% interquartile range), reaching net zero around 2050\"](https://www.ipcc.ch/sr15/chapter/spm/#article-spm-c). To simulate this in the electricity production industry, I have defined this reduction as an overall reduction in electricity power generation for each fossil fuel energy production source (coal, oil and natural gas). These reduction targets are visible in the graphs produced in this report.\n",
    "\n",
    "With all these factors, time-series modeling can assist with projection needs. This project will show the United State's energy production trends, and make recommendations for how to achieve the Paris Agreement Goals.\n",
    "\n",
    "Compared with the random walk baseline model, the selected models achieved its goal of realistically projecting construction / reduction trends in the electricity generation sector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "\n",
    "The planned steps I will follow for this project include: \n",
    "\n",
    "   1. Create a time series models that project energy production trends for each fuel source in the United States to the year 2050. \n",
    "   2. Plot all energy production trends against the projected energy demands of the United States.\n",
    "   3. Using interpolation, determine what reductions and construction increases are necessary to achieve the Paris Agreement goals. This will not use time series, as it's a determination of what trends must accomplish, rather than where the trends will go if left unchecked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Project 5 – What would it take to Meet the Paris Agreement Energy Production Targets?<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Achieving-the-Paris-Agreement-Goals:-Projecting-Energy-Production-Sources-in-the-United-States-With-Time-Series-Modeling\" data-toc-modified-id=\"Achieving-the-Paris-Agreement-Goals:-Projecting-Energy-Production-Sources-in-the-United-States-With-Time-Series-Modeling-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Achieving the Paris Agreement Goals: Projecting Energy Production Sources in the United States With Time Series Modeling</a></span></li><li><span><a href=\"#Business-Understanding\" data-toc-modified-id=\"Business-Understanding-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Business Understanding</a></span><ul class=\"toc-item\"><li><span><a href=\"#Stakeholder:-Environmental-Protection-Agency-(EPA)\" data-toc-modified-id=\"Stakeholder:-Environmental-Protection-Agency-(EPA)-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Stakeholder: <a href=\"https://www.epa.gov/\" rel=\"nofollow\" target=\"_blank\">Environmental Protection Agency (EPA)</a></a></span></li><li><span><a href=\"#Overview\" data-toc-modified-id=\"Overview-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Overview</a></span></li><li><span><a href=\"#Background:\" data-toc-modified-id=\"Background:-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Background:</a></span></li><li><span><a href=\"#Buisness-Problem:\" data-toc-modified-id=\"Buisness-Problem:-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Buisness Problem:</a></span></li><li><span><a href=\"#Time-Series-Modeling\" data-toc-modified-id=\"Time-Series-Modeling-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Time-Series Modeling</a></span></li><li><span><a href=\"#Methodology\" data-toc-modified-id=\"Methodology-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Methodology</a></span></li></ul></li><li><span><a href=\"#Table-of-Contents\" data-toc-modified-id=\"Table-of-Contents-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Table of Contents</a></span></li><li><span><a href=\"#Python-Libraries\" data-toc-modified-id=\"Python-Libraries-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Python Libraries</a></span></li><li><span><a href=\"#Data-Loading-From-Source,-EDA,-and-Cleaning\" data-toc-modified-id=\"Data-Loading-From-Source,-EDA,-and-Cleaning-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Data Loading From Source, EDA, and Cleaning</a></span></li><li><span><a href=\"#Initial-Modeling\" data-toc-modified-id=\"Initial-Modeling-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Initial Modeling</a></span><ul class=\"toc-item\"><li><span><a href=\"#Loading-the-Data\" data-toc-modified-id=\"Loading-the-Data-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Loading the Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Power-Generation-Model-Data\" data-toc-modified-id=\"Power-Generation-Model-Data-6.1.1\"><span class=\"toc-item-num\">6.1.1&nbsp;&nbsp;</span>Power Generation Model Data</a></span></li><li><span><a href=\"#Energy-Demand-Model-Data\" data-toc-modified-id=\"Energy-Demand-Model-Data-6.1.2\"><span class=\"toc-item-num\">6.1.2&nbsp;&nbsp;</span>Energy Demand Model Data</a></span></li><li><span><a href=\"#Pruning-the-Data-to-Just-USA\" data-toc-modified-id=\"Pruning-the-Data-to-Just-USA-6.1.3\"><span class=\"toc-item-num\">6.1.3&nbsp;&nbsp;</span>Pruning the Data to Just USA</a></span></li></ul></li><li><span><a href=\"#Visualizations\" data-toc-modified-id=\"Visualizations-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Visualizations</a></span></li></ul></li><li><span><a href=\"#Modeling-Energy-Fuel-Trends\" data-toc-modified-id=\"Modeling-Energy-Fuel-Trends-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Modeling Energy Fuel Trends</a></span><ul class=\"toc-item\"><li><span><a href=\"#Coal\" data-toc-modified-id=\"Coal-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Coal</a></span><ul class=\"toc-item\"><li><span><a href=\"#Distribution-Investigation\" data-toc-modified-id=\"Distribution-Investigation-7.1.1\"><span class=\"toc-item-num\">7.1.1&nbsp;&nbsp;</span>Distribution Investigation</a></span></li><li><span><a href=\"#Decomposing-The-Data\" data-toc-modified-id=\"Decomposing-The-Data-7.1.2\"><span class=\"toc-item-num\">7.1.2&nbsp;&nbsp;</span>Decomposing The Data</a></span></li><li><span><a href=\"#Checking-for-Stationarity-and-Flattening\" data-toc-modified-id=\"Checking-for-Stationarity-and-Flattening-7.1.3\"><span class=\"toc-item-num\">7.1.3&nbsp;&nbsp;</span>Checking for Stationarity and Flattening</a></span></li><li><span><a href=\"#Random-Walk-Model\" data-toc-modified-id=\"Random-Walk-Model-7.1.4\"><span class=\"toc-item-num\">7.1.4&nbsp;&nbsp;</span>Random Walk Model</a></span></li><li><span><a href=\"#Evaluating-Initial-AR-and-MA-Values-with-ACF-and-PACF-Plots\" data-toc-modified-id=\"Evaluating-Initial-AR-and-MA-Values-with-ACF-and-PACF-Plots-7.1.5\"><span class=\"toc-item-num\">7.1.5&nbsp;&nbsp;</span>Evaluating Initial AR and MA Values with ACF and PACF Plots</a></span></li><li><span><a href=\"#ARMA-Model\" data-toc-modified-id=\"ARMA-Model-7.1.6\"><span class=\"toc-item-num\">7.1.6&nbsp;&nbsp;</span>ARMA Model</a></span></li><li><span><a href=\"#ARIMA-Model-and-Grid-Search\" data-toc-modified-id=\"ARIMA-Model-and-Grid-Search-7.1.7\"><span class=\"toc-item-num\">7.1.7&nbsp;&nbsp;</span>ARIMA Model and Grid Search</a></span></li><li><span><a href=\"#ARIMA-Without-Transformation\" data-toc-modified-id=\"ARIMA-Without-Transformation-7.1.8\"><span class=\"toc-item-num\">7.1.8&nbsp;&nbsp;</span>ARIMA Without Transformation</a></span></li><li><span><a href=\"#Model-Selection\" data-toc-modified-id=\"Model-Selection-7.1.9\"><span class=\"toc-item-num\">7.1.9&nbsp;&nbsp;</span>Model Selection</a></span></li></ul></li><li><span><a href=\"#Gas\" data-toc-modified-id=\"Gas-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Gas</a></span><ul class=\"toc-item\"><li><span><a href=\"#Distribution-Investigation\" data-toc-modified-id=\"Distribution-Investigation-7.2.1\"><span class=\"toc-item-num\">7.2.1&nbsp;&nbsp;</span>Distribution Investigation</a></span></li><li><span><a href=\"#Decomposing-The-Data\" data-toc-modified-id=\"Decomposing-The-Data-7.2.2\"><span class=\"toc-item-num\">7.2.2&nbsp;&nbsp;</span>Decomposing The Data</a></span></li><li><span><a href=\"#Checking-for-Stationarity-and-Flattening\" data-toc-modified-id=\"Checking-for-Stationarity-and-Flattening-7.2.3\"><span class=\"toc-item-num\">7.2.3&nbsp;&nbsp;</span>Checking for Stationarity and Flattening</a></span></li><li><span><a href=\"#Random-Walk-Model\" data-toc-modified-id=\"Random-Walk-Model-7.2.4\"><span class=\"toc-item-num\">7.2.4&nbsp;&nbsp;</span>Random Walk Model</a></span></li><li><span><a href=\"#Evaluating-Initial-AR-and-MA-Values-with-ACF-and-PACF-Plots\" data-toc-modified-id=\"Evaluating-Initial-AR-and-MA-Values-with-ACF-and-PACF-Plots-7.2.5\"><span class=\"toc-item-num\">7.2.5&nbsp;&nbsp;</span>Evaluating Initial AR and MA Values with ACF and PACF Plots</a></span></li><li><span><a href=\"#ARMA-Model\" data-toc-modified-id=\"ARMA-Model-7.2.6\"><span class=\"toc-item-num\">7.2.6&nbsp;&nbsp;</span>ARMA Model</a></span></li><li><span><a href=\"#ARIMA-Model-and-Grid-Search\" data-toc-modified-id=\"ARIMA-Model-and-Grid-Search-7.2.7\"><span class=\"toc-item-num\">7.2.7&nbsp;&nbsp;</span>ARIMA Model and Grid Search</a></span></li><li><span><a href=\"#ARIMA-Without-Transformation\" data-toc-modified-id=\"ARIMA-Without-Transformation-7.2.8\"><span class=\"toc-item-num\">7.2.8&nbsp;&nbsp;</span>ARIMA Without Transformation</a></span></li><li><span><a href=\"#Model-Selection\" data-toc-modified-id=\"Model-Selection-7.2.9\"><span class=\"toc-item-num\">7.2.9&nbsp;&nbsp;</span>Model Selection</a></span></li></ul></li><li><span><a href=\"#Oil\" data-toc-modified-id=\"Oil-7.3\"><span class=\"toc-item-num\">7.3&nbsp;&nbsp;</span>Oil</a></span><ul class=\"toc-item\"><li><span><a href=\"#Distribution-Investigation\" data-toc-modified-id=\"Distribution-Investigation-7.3.1\"><span class=\"toc-item-num\">7.3.1&nbsp;&nbsp;</span>Distribution Investigation</a></span></li><li><span><a href=\"#Decomposing-The-Data\" data-toc-modified-id=\"Decomposing-The-Data-7.3.2\"><span class=\"toc-item-num\">7.3.2&nbsp;&nbsp;</span>Decomposing The Data</a></span></li><li><span><a href=\"#Checking-for-Stationarity-and-Flattening\" data-toc-modified-id=\"Checking-for-Stationarity-and-Flattening-7.3.3\"><span class=\"toc-item-num\">7.3.3&nbsp;&nbsp;</span>Checking for Stationarity and Flattening</a></span></li><li><span><a href=\"#Random-Walk-Model\" data-toc-modified-id=\"Random-Walk-Model-7.3.4\"><span class=\"toc-item-num\">7.3.4&nbsp;&nbsp;</span>Random Walk Model</a></span></li><li><span><a href=\"#Evaluating-Initial-AR-and-MA-Values-with-ACF-and-PACF-Plots\" data-toc-modified-id=\"Evaluating-Initial-AR-and-MA-Values-with-ACF-and-PACF-Plots-7.3.5\"><span class=\"toc-item-num\">7.3.5&nbsp;&nbsp;</span>Evaluating Initial AR and MA Values with ACF and PACF Plots</a></span></li><li><span><a href=\"#ARMA-Model\" data-toc-modified-id=\"ARMA-Model-7.3.6\"><span class=\"toc-item-num\">7.3.6&nbsp;&nbsp;</span>ARMA Model</a></span></li><li><span><a href=\"#ARIMA-Model-and-Grid-Search\" data-toc-modified-id=\"ARIMA-Model-and-Grid-Search-7.3.7\"><span class=\"toc-item-num\">7.3.7&nbsp;&nbsp;</span>ARIMA Model and Grid Search</a></span></li><li><span><a href=\"#ARIMA-Without-Transformation\" data-toc-modified-id=\"ARIMA-Without-Transformation-7.3.8\"><span class=\"toc-item-num\">7.3.8&nbsp;&nbsp;</span>ARIMA Without Transformation</a></span></li><li><span><a href=\"#Model-Selection\" data-toc-modified-id=\"Model-Selection-7.3.9\"><span class=\"toc-item-num\">7.3.9&nbsp;&nbsp;</span>Model Selection</a></span></li></ul></li><li><span><a href=\"#Nuclear\" data-toc-modified-id=\"Nuclear-7.4\"><span class=\"toc-item-num\">7.4&nbsp;&nbsp;</span>Nuclear</a></span><ul class=\"toc-item\"><li><span><a href=\"#Distribution-Investigation\" data-toc-modified-id=\"Distribution-Investigation-7.4.1\"><span class=\"toc-item-num\">7.4.1&nbsp;&nbsp;</span>Distribution Investigation</a></span></li><li><span><a href=\"#Decomposing-The-Data\" data-toc-modified-id=\"Decomposing-The-Data-7.4.2\"><span class=\"toc-item-num\">7.4.2&nbsp;&nbsp;</span>Decomposing The Data</a></span></li><li><span><a href=\"#Checking-for-Stationarity-and-Flattening\" data-toc-modified-id=\"Checking-for-Stationarity-and-Flattening-7.4.3\"><span class=\"toc-item-num\">7.4.3&nbsp;&nbsp;</span>Checking for Stationarity and Flattening</a></span></li><li><span><a href=\"#Random-Walk-Model\" data-toc-modified-id=\"Random-Walk-Model-7.4.4\"><span class=\"toc-item-num\">7.4.4&nbsp;&nbsp;</span>Random Walk Model</a></span></li><li><span><a href=\"#Evaluating-Initial-AR-and-MA-Values-with-ACF-and-PACF-Plots\" data-toc-modified-id=\"Evaluating-Initial-AR-and-MA-Values-with-ACF-and-PACF-Plots-7.4.5\"><span class=\"toc-item-num\">7.4.5&nbsp;&nbsp;</span>Evaluating Initial AR and MA Values with ACF and PACF Plots</a></span></li><li><span><a href=\"#ARMA-Model\" data-toc-modified-id=\"ARMA-Model-7.4.6\"><span class=\"toc-item-num\">7.4.6&nbsp;&nbsp;</span>ARMA Model</a></span></li><li><span><a href=\"#ARIMA-Model-and-Grid-Search\" data-toc-modified-id=\"ARIMA-Model-and-Grid-Search-7.4.7\"><span class=\"toc-item-num\">7.4.7&nbsp;&nbsp;</span>ARIMA Model and Grid Search</a></span></li><li><span><a href=\"#ARIMA-Without-Transformation\" data-toc-modified-id=\"ARIMA-Without-Transformation-7.4.8\"><span class=\"toc-item-num\">7.4.8&nbsp;&nbsp;</span>ARIMA Without Transformation</a></span></li><li><span><a href=\"#Model-Selection\" data-toc-modified-id=\"Model-Selection-7.4.9\"><span class=\"toc-item-num\">7.4.9&nbsp;&nbsp;</span>Model Selection</a></span></li></ul></li><li><span><a href=\"#Hydro\" data-toc-modified-id=\"Hydro-7.5\"><span class=\"toc-item-num\">7.5&nbsp;&nbsp;</span>Hydro</a></span><ul class=\"toc-item\"><li><span><a href=\"#Distribution-Investigation\" data-toc-modified-id=\"Distribution-Investigation-7.5.1\"><span class=\"toc-item-num\">7.5.1&nbsp;&nbsp;</span>Distribution Investigation</a></span></li><li><span><a href=\"#Decomposing-The-Data\" data-toc-modified-id=\"Decomposing-The-Data-7.5.2\"><span class=\"toc-item-num\">7.5.2&nbsp;&nbsp;</span>Decomposing The Data</a></span></li><li><span><a href=\"#Checking-for-Stationarity-and-Flattening\" data-toc-modified-id=\"Checking-for-Stationarity-and-Flattening-7.5.3\"><span class=\"toc-item-num\">7.5.3&nbsp;&nbsp;</span>Checking for Stationarity and Flattening</a></span></li><li><span><a href=\"#Random-Walk-Model\" data-toc-modified-id=\"Random-Walk-Model-7.5.4\"><span class=\"toc-item-num\">7.5.4&nbsp;&nbsp;</span>Random Walk Model</a></span></li><li><span><a href=\"#Evaluating-Initial-AR-and-MA-Values-with-ACF-and-PACF-Plots\" data-toc-modified-id=\"Evaluating-Initial-AR-and-MA-Values-with-ACF-and-PACF-Plots-7.5.5\"><span class=\"toc-item-num\">7.5.5&nbsp;&nbsp;</span>Evaluating Initial AR and MA Values with ACF and PACF Plots</a></span></li><li><span><a href=\"#ARMA-Model\" data-toc-modified-id=\"ARMA-Model-7.5.6\"><span class=\"toc-item-num\">7.5.6&nbsp;&nbsp;</span>ARMA Model</a></span></li><li><span><a href=\"#ARIMA-Model-and-Grid-Search\" data-toc-modified-id=\"ARIMA-Model-and-Grid-Search-7.5.7\"><span class=\"toc-item-num\">7.5.7&nbsp;&nbsp;</span>ARIMA Model and Grid Search</a></span></li><li><span><a href=\"#ARIMA-Without-Transformation\" data-toc-modified-id=\"ARIMA-Without-Transformation-7.5.8\"><span class=\"toc-item-num\">7.5.8&nbsp;&nbsp;</span>ARIMA Without Transformation</a></span></li><li><span><a href=\"#Model-Selection\" data-toc-modified-id=\"Model-Selection-7.5.9\"><span class=\"toc-item-num\">7.5.9&nbsp;&nbsp;</span>Model Selection</a></span></li></ul></li><li><span><a href=\"#Bioenergy\" data-toc-modified-id=\"Bioenergy-7.6\"><span class=\"toc-item-num\">7.6&nbsp;&nbsp;</span>Bioenergy</a></span><ul class=\"toc-item\"><li><span><a href=\"#Distribution-Investigation\" data-toc-modified-id=\"Distribution-Investigation-7.6.1\"><span class=\"toc-item-num\">7.6.1&nbsp;&nbsp;</span>Distribution Investigation</a></span></li><li><span><a href=\"#Decomposing-The-Data\" data-toc-modified-id=\"Decomposing-The-Data-7.6.2\"><span class=\"toc-item-num\">7.6.2&nbsp;&nbsp;</span>Decomposing The Data</a></span></li><li><span><a href=\"#Checking-for-Stationarity-and-Flattening\" data-toc-modified-id=\"Checking-for-Stationarity-and-Flattening-7.6.3\"><span class=\"toc-item-num\">7.6.3&nbsp;&nbsp;</span>Checking for Stationarity and Flattening</a></span></li><li><span><a href=\"#Random-Walk-Model\" data-toc-modified-id=\"Random-Walk-Model-7.6.4\"><span class=\"toc-item-num\">7.6.4&nbsp;&nbsp;</span>Random Walk Model</a></span></li><li><span><a href=\"#Evaluating-Initial-AR-and-MA-Values-with-ACF-and-PACF-Plots\" data-toc-modified-id=\"Evaluating-Initial-AR-and-MA-Values-with-ACF-and-PACF-Plots-7.6.5\"><span class=\"toc-item-num\">7.6.5&nbsp;&nbsp;</span>Evaluating Initial AR and MA Values with ACF and PACF Plots</a></span></li><li><span><a href=\"#ARMA-Model\" data-toc-modified-id=\"ARMA-Model-7.6.6\"><span class=\"toc-item-num\">7.6.6&nbsp;&nbsp;</span>ARMA Model</a></span></li><li><span><a href=\"#ARIMA-Model-and-Grid-Search\" data-toc-modified-id=\"ARIMA-Model-and-Grid-Search-7.6.7\"><span class=\"toc-item-num\">7.6.7&nbsp;&nbsp;</span>ARIMA Model and Grid Search</a></span></li><li><span><a href=\"#ARIMA-Without-Transformation\" data-toc-modified-id=\"ARIMA-Without-Transformation-7.6.8\"><span class=\"toc-item-num\">7.6.8&nbsp;&nbsp;</span>ARIMA Without Transformation</a></span></li><li><span><a href=\"#Model-Selection\" data-toc-modified-id=\"Model-Selection-7.6.9\"><span class=\"toc-item-num\">7.6.9&nbsp;&nbsp;</span>Model Selection</a></span></li></ul></li><li><span><a href=\"#Wind\" data-toc-modified-id=\"Wind-7.7\"><span class=\"toc-item-num\">7.7&nbsp;&nbsp;</span>Wind</a></span><ul class=\"toc-item\"><li><span><a href=\"#Distribution-Investigation\" data-toc-modified-id=\"Distribution-Investigation-7.7.1\"><span class=\"toc-item-num\">7.7.1&nbsp;&nbsp;</span>Distribution Investigation</a></span></li><li><span><a href=\"#Decomposing-The-Data\" data-toc-modified-id=\"Decomposing-The-Data-7.7.2\"><span class=\"toc-item-num\">7.7.2&nbsp;&nbsp;</span>Decomposing The Data</a></span></li><li><span><a href=\"#Checking-for-Stationarity-and-Flattening\" data-toc-modified-id=\"Checking-for-Stationarity-and-Flattening-7.7.3\"><span class=\"toc-item-num\">7.7.3&nbsp;&nbsp;</span>Checking for Stationarity and Flattening</a></span></li><li><span><a href=\"#Random-Walk-Model\" data-toc-modified-id=\"Random-Walk-Model-7.7.4\"><span class=\"toc-item-num\">7.7.4&nbsp;&nbsp;</span>Random Walk Model</a></span></li><li><span><a href=\"#Evaluating-Initial-AR-and-MA-Values-with-ACF-and-PACF-Plots\" data-toc-modified-id=\"Evaluating-Initial-AR-and-MA-Values-with-ACF-and-PACF-Plots-7.7.5\"><span class=\"toc-item-num\">7.7.5&nbsp;&nbsp;</span>Evaluating Initial AR and MA Values with ACF and PACF Plots</a></span></li><li><span><a href=\"#ARMA-Model\" data-toc-modified-id=\"ARMA-Model-7.7.6\"><span class=\"toc-item-num\">7.7.6&nbsp;&nbsp;</span>ARMA Model</a></span></li><li><span><a href=\"#ARIMA-Without-Transformation\" data-toc-modified-id=\"ARIMA-Without-Transformation-7.7.7\"><span class=\"toc-item-num\">7.7.7&nbsp;&nbsp;</span>ARIMA Without Transformation</a></span></li><li><span><a href=\"#Model-Selection\" data-toc-modified-id=\"Model-Selection-7.7.8\"><span class=\"toc-item-num\">7.7.8&nbsp;&nbsp;</span>Model Selection</a></span></li></ul></li><li><span><a href=\"#Solar\" data-toc-modified-id=\"Solar-7.8\"><span class=\"toc-item-num\">7.8&nbsp;&nbsp;</span>Solar</a></span><ul class=\"toc-item\"><li><span><a href=\"#Distribution-Investigation\" data-toc-modified-id=\"Distribution-Investigation-7.8.1\"><span class=\"toc-item-num\">7.8.1&nbsp;&nbsp;</span>Distribution Investigation</a></span></li><li><span><a href=\"#Decomposing-The-Data\" data-toc-modified-id=\"Decomposing-The-Data-7.8.2\"><span class=\"toc-item-num\">7.8.2&nbsp;&nbsp;</span>Decomposing The Data</a></span></li><li><span><a href=\"#Checking-for-Stationarity-and-Flattening\" data-toc-modified-id=\"Checking-for-Stationarity-and-Flattening-7.8.3\"><span class=\"toc-item-num\">7.8.3&nbsp;&nbsp;</span>Checking for Stationarity and Flattening</a></span></li><li><span><a href=\"#Random-Walk-Model\" data-toc-modified-id=\"Random-Walk-Model-7.8.4\"><span class=\"toc-item-num\">7.8.4&nbsp;&nbsp;</span>Random Walk Model</a></span></li><li><span><a href=\"#Evaluating-Initial-AR-and-MA-Values-with-ACF-and-PACF-Plots\" data-toc-modified-id=\"Evaluating-Initial-AR-and-MA-Values-with-ACF-and-PACF-Plots-7.8.5\"><span class=\"toc-item-num\">7.8.5&nbsp;&nbsp;</span>Evaluating Initial AR and MA Values with ACF and PACF Plots</a></span></li><li><span><a href=\"#ARMA-Model\" data-toc-modified-id=\"ARMA-Model-7.8.6\"><span class=\"toc-item-num\">7.8.6&nbsp;&nbsp;</span>ARMA Model</a></span></li><li><span><a href=\"#ARIMA-Model-and-Grid-Search\" data-toc-modified-id=\"ARIMA-Model-and-Grid-Search-7.8.7\"><span class=\"toc-item-num\">7.8.7&nbsp;&nbsp;</span>ARIMA Model and Grid Search</a></span></li><li><span><a href=\"#ARIMA-Without-Transformation\" data-toc-modified-id=\"ARIMA-Without-Transformation-7.8.8\"><span class=\"toc-item-num\">7.8.8&nbsp;&nbsp;</span>ARIMA Without Transformation</a></span></li><li><span><a href=\"#Model-Selection\" data-toc-modified-id=\"Model-Selection-7.8.9\"><span class=\"toc-item-num\">7.8.9&nbsp;&nbsp;</span>Model Selection</a></span></li></ul></li><li><span><a href=\"#Other-Renewables\" data-toc-modified-id=\"Other-Renewables-7.9\"><span class=\"toc-item-num\">7.9&nbsp;&nbsp;</span>Other Renewables</a></span><ul class=\"toc-item\"><li><span><a href=\"#Distribution-Investigation\" data-toc-modified-id=\"Distribution-Investigation-7.9.1\"><span class=\"toc-item-num\">7.9.1&nbsp;&nbsp;</span>Distribution Investigation</a></span></li><li><span><a href=\"#Decomposing-The-Data\" data-toc-modified-id=\"Decomposing-The-Data-7.9.2\"><span class=\"toc-item-num\">7.9.2&nbsp;&nbsp;</span>Decomposing The Data</a></span></li><li><span><a href=\"#Checking-for-Stationarity-and-Flattening\" data-toc-modified-id=\"Checking-for-Stationarity-and-Flattening-7.9.3\"><span class=\"toc-item-num\">7.9.3&nbsp;&nbsp;</span>Checking for Stationarity and Flattening</a></span></li><li><span><a href=\"#Random-Walk-Model\" data-toc-modified-id=\"Random-Walk-Model-7.9.4\"><span class=\"toc-item-num\">7.9.4&nbsp;&nbsp;</span>Random Walk Model</a></span></li><li><span><a href=\"#Evaluating-Initial-AR-and-MA-Values-with-ACF-and-PACF-Plots\" data-toc-modified-id=\"Evaluating-Initial-AR-and-MA-Values-with-ACF-and-PACF-Plots-7.9.5\"><span class=\"toc-item-num\">7.9.5&nbsp;&nbsp;</span>Evaluating Initial AR and MA Values with ACF and PACF Plots</a></span></li><li><span><a href=\"#ARMA-Model\" data-toc-modified-id=\"ARMA-Model-7.9.6\"><span class=\"toc-item-num\">7.9.6&nbsp;&nbsp;</span>ARMA Model</a></span></li><li><span><a href=\"#ARIMA-Model-and-Grid-Search\" data-toc-modified-id=\"ARIMA-Model-and-Grid-Search-7.9.7\"><span class=\"toc-item-num\">7.9.7&nbsp;&nbsp;</span>ARIMA Model and Grid Search</a></span></li><li><span><a href=\"#ARIMA-Without-Transformation\" data-toc-modified-id=\"ARIMA-Without-Transformation-7.9.8\"><span class=\"toc-item-num\">7.9.8&nbsp;&nbsp;</span>ARIMA Without Transformation</a></span></li><li><span><a href=\"#Model-Selection\" data-toc-modified-id=\"Model-Selection-7.9.9\"><span class=\"toc-item-num\">7.9.9&nbsp;&nbsp;</span>Model Selection</a></span></li></ul></li></ul></li><li><span><a href=\"#Graphing-Energy-Production-Sources\" data-toc-modified-id=\"Graphing-Energy-Production-Sources-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Graphing Energy Production Sources</a></span></li><li><span><a href=\"#Reduction-in-Natural-Gas-Energy-Production-to-Meet-Paris-Agreement-Targets\" data-toc-modified-id=\"Reduction-in-Natural-Gas-Energy-Production-to-Meet-Paris-Agreement-Targets-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Reduction in Natural Gas Energy Production to Meet Paris Agreement Targets</a></span></li><li><span><a href=\"#Conclusion\" data-toc-modified-id=\"Conclusion-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Conclusion</a></span><ul class=\"toc-item\"><li><span><a href=\"#Limitations-of-Scope-/-Provided-Data\" data-toc-modified-id=\"Limitations-of-Scope-/-Provided-Data-10.1\"><span class=\"toc-item-num\">10.1&nbsp;&nbsp;</span>Limitations of Scope / Provided Data</a></span></li><li><span><a href=\"#Future-Research-Opportunities\" data-toc-modified-id=\"Future-Research-Opportunities-10.2\"><span class=\"toc-item-num\">10.2&nbsp;&nbsp;</span>Future Research Opportunities</a></span></li><li><span><a href=\"#Recommendations\" data-toc-modified-id=\"Recommendations-10.3\"><span class=\"toc-item-num\">10.3&nbsp;&nbsp;</span>Recommendations</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrames and computation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Graphing\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# To supress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from statsmodels.tools.sm_exceptions import ValueWarning\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "warnings.simplefilter('ignore', ValueWarning)\n",
    "warnings.simplefilter('ignore', ConvergenceWarning)\n",
    "\n",
    "# For distribution calculations.\n",
    "import scipy.stats as stats\n",
    "\n",
    "# For datetime conversions\n",
    "import datetime as dt\n",
    "\n",
    "# Decompose to check for seasonality\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Check for Stationarity\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Plot ACF / PACF\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "# Plot with Arima\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# For testing and metrics\n",
    "import sklearn as sk\n",
    "import statsmodels.api as sm\n",
    "from sklearn import metrics\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# For creating iterations\n",
    "import itertools\n",
    "# Setting DataFrame Display Settings\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 6)\n",
    "# Setting Pandas Series Display Settings\n",
    "\n",
    "# Formatting decimals to show three numbers after the point.\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "# Plotly for a tree map\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading From Source, EDA, and Cleaning\n",
    "\n",
    "For details on the origins of this project's data, Exploratory Data Analysis, and Cleaning, see the Jupyter Notebook file: [data_import_cleaning_export.ipynb](https://github.com/FunkyTable/Project-5/blob/main/data_import_cleaning_export.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Modeling\n",
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power Generation Model Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Data/Export/df_hist_elec_yr_reg.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_hist_elec \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData/Export/df_hist_elec_yr_reg.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mANSI\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m df_hist_elec[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df_hist_elec\u001b[38;5;241m.\u001b[39mYear, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m df_hist_elec\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m df_hist_elec[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\elec-env\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\elec-env\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\elec-env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\elec-env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\elec-env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\elec-env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1736\u001b[0m     f,\n\u001b[0;32m   1737\u001b[0m     mode,\n\u001b[0;32m   1738\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1739\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1740\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1741\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1742\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1743\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1744\u001b[0m )\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\elec-env\\Lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    859\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    860\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    861\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data/Export/df_hist_elec_yr_reg.csv'"
     ]
    }
   ],
   "source": [
    "df_hist_elec = pd.read_csv(\n",
    "    \"Data/Export/df_hist_elec_yr_reg.csv\",\n",
    "    encoding='ANSI')\n",
    "\n",
    "df_hist_elec['Year'] = pd.to_datetime(df_hist_elec.Year, format='%Y')\n",
    "\n",
    "df_hist_elec.index = df_hist_elec['Year']\n",
    "df_hist_elec = df_hist_elec.iloc[:,1:]\n",
    "\n",
    "df_hist_elec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Energy Demand Model Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Historical energy demand\n",
    "df_hist_dem = pd.read_csv(\n",
    "    \"Data/Export/df_hist_dem_yr_reg.csv\",\n",
    "    encoding='ANSI')\n",
    "\n",
    "df_hist_dem['Year'] = pd.to_datetime(df_hist_dem.Year, format='%Y')\n",
    "df_hist_dem.index = df_hist_dem['Year']\n",
    "df_hist_dem = df_hist_dem.iloc[:,1:]\n",
    "\n",
    "df_hist_dem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Projected energy demand, Stated Policies\n",
    "df_proj_dem_stat = pd.read_csv(\n",
    "    \"Data/Export/df_proj_dem_stat_yr.csv\",\n",
    "    encoding='ANSI')\n",
    "\n",
    "df_proj_dem_stat['Year'] = pd.to_datetime(df_proj_dem_stat.Year, format='%Y')\n",
    "df_proj_dem_stat.index = df_proj_dem_stat['Year']\n",
    "df_proj_dem_stat = df_proj_dem_stat.iloc[:,2:]\n",
    "# Dropping the 2010 data and adding the historic demand for 2019 for graphing\n",
    "# purposes.\n",
    "\n",
    "df_proj_dem_stat.drop(index = df_proj_dem_stat.index[0:3],inplace = True)\n",
    "\n",
    "jnk = df_hist_dem.iloc[-1:,:]\n",
    "jnk.columns = df_proj_dem_stat.columns\n",
    "df_proj_dem_stat = pd.concat([jnk, df_proj_dem_stat], axis = 0)\n",
    "\n",
    "df_proj_dem_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pruning the Data to Just USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I originally thought I would perform this analysis on the entire world, but\n",
    "# I settled for just the United States. I left this here in case I ever return\n",
    "# to the broader scope of this project.\n",
    "# Creating lists of column names to easily call on different types of data.\n",
    "\n",
    "# Energy Types including all regions and countries.\n",
    "oth = []\n",
    "bio = []\n",
    "sol = []\n",
    "wnd = []\n",
    "hyd = []\n",
    "nuc = []\n",
    "oil = []\n",
    "gas = []\n",
    "coal = []\n",
    "\n",
    "# Energy Types including all regions.\n",
    "ear = []\n",
    "apc = []\n",
    "nam = []\n",
    "erp = []\n",
    "eur = []\n",
    "csa = []\n",
    "mde = []\n",
    "afc = []\n",
    "\n",
    "# Energy Types including all countries.\n",
    "usa = []\n",
    "chn = []\n",
    "eu =  []\n",
    "jpn = []\n",
    "rus = []\n",
    "ind = []\n",
    "sea = []\n",
    "bra = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling the lists with the correct column names to easily call on\n",
    "# different organizations of data.\n",
    "for col in df_hist_elec.columns:\n",
    "    # Organized by Fuel Type\n",
    "    if 'Other' in col:\n",
    "        oth.append(col)\n",
    "    elif 'Bioenergy' in col:\n",
    "        bio.append(col)\n",
    "    elif 'Solar' in col:\n",
    "        sol.append(col)\n",
    "    elif 'Wind' in col:\n",
    "        wnd.append(col)\n",
    "    elif 'Hydro' in col:\n",
    "        hyd.append(col)\n",
    "    elif 'Nuclear' in col:\n",
    "        nuc.append(col)\n",
    "    elif 'Oil' in col:\n",
    "        oil.append(col)\n",
    "    elif 'Gas' in col:\n",
    "        gas.append(col)\n",
    "    elif 'Coal' in col:\n",
    "        coal.append(col)\n",
    "    else:\n",
    "        print(col, 'not found.')\n",
    "\n",
    "    # Regions lists\n",
    "    if 'Earth' in col:\n",
    "        ear.append(col)\n",
    "    elif 'Asia Pacific' in col:\n",
    "        apc.append(col)\n",
    "    elif 'North America' in col:\n",
    "        nam.append(col)\n",
    "    elif 'Europe ' in col:\n",
    "        erp.append(col)\n",
    "    elif 'Eurasia' in col:\n",
    "        eur.append(col)\n",
    "    elif 'Central & South America' in col:\n",
    "        csa.append(col)\n",
    "    elif 'Middle East' in col:\n",
    "        mde.append(col)\n",
    "    elif 'Africa' in col:\n",
    "        afc.append(col)\n",
    "\n",
    "    # Country lists\n",
    "    elif 'United States' in col:\n",
    "        usa.append(col)\n",
    "    elif 'China' in col:\n",
    "        chn.append(col)\n",
    "    elif 'European Union' in col:\n",
    "        eu.append(col)\n",
    "    elif 'Japan' in col:\n",
    "        jpn.append(col)\n",
    "    elif 'Russia' in col:\n",
    "        rus.append(col)\n",
    "    elif 'India' in col:\n",
    "        ind.append(col)\n",
    "    elif 'SouthEast Asia' in col:\n",
    "        sea.append(col)\n",
    "    elif 'Brazil' in col:\n",
    "        bra.append(col)\n",
    "    else:\n",
    "        print(col, 'not found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = df_hist_elec[usa].copy()\n",
    "model_data = model_data.iloc[:,[8,7,6,5,4,1,3,2,0]]\n",
    "model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will create a line chart showing the trends of electricity generation in America."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line8 = model_data.iloc[:,8].plot(label = 'Other Renewable')\n",
    "line7 = model_data.iloc[:,7].plot(label = 'Solar')\n",
    "line6 = model_data.iloc[:,6].plot(label = 'Wind')\n",
    "line5 = model_data.iloc[:,5].plot(label = 'Bioenergy')\n",
    "line4 = model_data.iloc[:,4].plot(label = 'Hydro')\n",
    "line3 = model_data.iloc[:,3].plot(label = 'Nuclear')\n",
    "line2 = model_data.iloc[:,2].plot(label = 'Oil')\n",
    "line1 = model_data.iloc[:,1].plot(label = 'Gas')\n",
    "line0 = model_data.iloc[:,0].plot(figsize=(15,4),label = 'Coal')\n",
    "\n",
    "\n",
    "plt.legend(loc = 6)\n",
    "plt.title('USA Historical Power Generation Methods (TWh) 2000–2021');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will create a stacked graph for the same data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s_energy_hist(his_elec, his_dem, title, s=0):\n",
    "    \n",
    "    df_names = list(his_elec.columns)\n",
    "    if s>0:\n",
    "        for i in range(len(df_names)):\n",
    "            df_names[i] = df_names[i][s:]\n",
    "    his_dem.name = his_dem.iloc[:,0:1].columns[0][s:]\n",
    "\n",
    "    fig = plt.figure(figsize = (20,12))\n",
    "    plt.title(title, size = 15)\n",
    "\n",
    "    # Printing the demand\n",
    "    plt.plot(his_dem.index, his_dem.iloc[:,0], \n",
    "             label = his_dem.name)\n",
    "    \n",
    "    his_elec_lst = []\n",
    "    for i in range(len(his_elec.columns)):\n",
    "        his_elec_lst.append(his_elec.iloc[:,i])\n",
    "            \n",
    "    # Printing the stacked energy production\n",
    "    plt.gca().set_prop_cycle(None)\n",
    "    plt.stackplot(his_elec.index, his_elec_lst, labels = df_names)\n",
    "\n",
    "    # Formatting\n",
    "    plt.xlabel('Year', size = 15)\n",
    "    plt.ylabel('TWh', size = 15)\n",
    "    plt.xticks(size=15)\n",
    "    plt.yticks(size=15)\n",
    "    plt.legend(loc=6)\n",
    "    # show the graph\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacked_energy_hist(his_en, his_dem, title, s=0):\n",
    "    \n",
    "    df_names = list(his_en.columns)\n",
    "    if s>0:\n",
    "        for i in range(len(df_names)):\n",
    "            df_names[i] = df_names[i][s:]\n",
    "    his_dem.name = his_dem.iloc[:,0:1].columns[0][s:]\n",
    "\n",
    "    fig = plt.figure(figsize = (20,12))\n",
    "    plt.title(title, size = 15)\n",
    "\n",
    "    # Printing the demand\n",
    "    plt.plot(his_dem.index, his_dem.iloc[:,0], \n",
    "             label = his_dem.name)\n",
    "    \n",
    "    his_en_lst = []\n",
    "    for i in range(len(his_en.columns)):\n",
    "        his_en_lst.append(his_en.iloc[:,i])\n",
    "            \n",
    "    # Printing the stacked energy production\n",
    "    plt.gca().set_prop_cycle(None)\n",
    "    plt.stackplot(his_en.index, his_en_lst, labels = df_names)\n",
    "\n",
    "    # Formatting\n",
    "    plt.xlabel('Year', size = 15)\n",
    "    plt.ylabel('TWh', size = 15)\n",
    "    plt.xticks(size=15)\n",
    "    plt.yticks(size=15)\n",
    "    plt.legend(loc=6)\n",
    "    # show the graph\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stacked_energy_hist(model_data.iloc[:,::-1], df_hist_dem.iloc[:,8:9],\n",
    "                   'United States Historic Energy Demand and Sources', 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will create a Treemap of current electricity production percentages in America."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 9)\n",
    "figure_data = pd.DataFrame(model_data.iloc[21:22,0:8].transpose().copy(),\n",
    "                           columns = ['Electricity Production'])\n",
    "\n",
    "figure_data['KWh'] = model_data.iloc[21:22,0:8].transpose().values\n",
    "\n",
    "total = np.sum(figure_data['KWh'])\n",
    "\n",
    "\n",
    "for idx in figure_data.index:\n",
    "    figure_data.loc[idx, 'Electricity Production'] = idx[14:]\n",
    "    figure_data.loc[idx, 'Percentage'] = figure_data.loc[idx, 'KWh']/total\n",
    "\n",
    "figure_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.treemap(figure_data, path = ['Electricity Production'],\n",
    "                 values = 'KWh',\n",
    "                 title = 'Electricty Production in the United States')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Energy Fuel Trends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coal\n",
    "### Distribution Investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of values.\n",
    "def hist(df):\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "    df.plot.hist(ax=ax, density = True, grid=False, label = 'Histogram');\n",
    "    df.plot.kde(ax=ax, ind=50, label = 'Kernal Density Estimation')\n",
    "    plt.title('Histogram with Kernal Density Estimation for \\n'+df.columns[0])\n",
    "    plt.ylabel('Density', fontsize=14)\n",
    "    plt.xlabel('Power Generation (TWh)', fontsize=14)\n",
    "    plt.legend([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s_block(df, compare = pd.DataFrame()):\n",
    "    block = pd.DataFrame([[df.columns[0], np.mean(df)[0], np.median(df), \n",
    "                    np.std(df)[0], stats.skew(df)[0], stats.kurtosis(df)[0]]],\n",
    "                         columns = ['Dataset', 'Mean', 'Median',\n",
    "                                    'Standard Deviation', 'Skew',\n",
    "                                    'Fisher Kurtosis'])\n",
    "    if ~compare.empty:\n",
    "        block = pd.concat([compare, block], axis=0)\n",
    "        block.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist(model_data.iloc[:,0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_block = s_block(model_data.iloc[:,0:1])\n",
    "stats_block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is skewed negatively with flat tails on either side."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposing The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decomp_graph(df, mod = 'additive'):\n",
    "    decomposition = seasonal_decompose(df, mod)\n",
    "\n",
    "    # Gather the trend, seasonality, and residuals \n",
    "    trend = decomposition.trend\n",
    "    seasonal = decomposition.seasonal\n",
    "    residual = decomposition.resid\n",
    "\n",
    "    # Plot gathered statistics\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.subplot(411)\n",
    "    plt.title(df.columns[0])\n",
    "    plt.plot(df, label='Original', color='blue')\n",
    "    plt.legend(loc='best')\n",
    "    plt.subplot(412)\n",
    "    plt.plot(trend, label='Trend', color='blue')\n",
    "    plt.legend(loc='best')\n",
    "    plt.subplot(413)\n",
    "    plt.plot(seasonal,label='Seasonality', color='blue')\n",
    "    plt.legend(loc='best')\n",
    "    plt.subplot(414)\n",
    "    plt.plot(residual, label='Residuals', color='blue')\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomp_graph(model_data.iloc[:,0:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No seasonality or residuals. I'll check for stationarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for Stationarity and Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_test(df):\n",
    "    dftest = adfuller(df.dropna())\n",
    "\n",
    "    # Extract and display test results in a user friendly manner\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic', 'p-value',\n",
    "                                             '#Lags Used',\n",
    "                                             'Number of Observations Used'])\n",
    "\n",
    "    for key,value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)'%key] = value\n",
    "\n",
    "    print (df.columns[0] + '\\nResults of Dickey-Fuller test: \\n')\n",
    "    print(dfoutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_std(df, title='Rolling Mean & Standard Deviation', s=0):\n",
    "    roll_mean = df.rolling(window=8, center=False).mean()\n",
    "    roll_std = df.rolling(window=8, center=False).std()\n",
    "    fig = plt.figure(figsize=(8,4))\n",
    "    plt.plot(df, color='blue', label=str(df.columns[0])[s:])\n",
    "    plt.plot(roll_mean, color='red', label=str(\n",
    "                                        df.columns[0])[s:]+' -Rolling Mean')\n",
    "    plt.plot(roll_std, color='black', label=str(\n",
    "                                        df.columns[0])[s:]+' -Rolling Std')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title(df.columns[0] + '\\n' + title)\n",
    "    plt.ylabel('Power Generation (TWh)', fontsize=14)\n",
    "    plt.xlabel('Year', fontsize=14)\n",
    "    plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stationarity_check(df, t = 'Rolling Mean & Standard Deviation', s=0):\n",
    "    df_test(df)\n",
    "    mean_std(df, title=t, s=s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 30)\n",
    "stationarity_check(model_data.iloc[:,0:1], s=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not close to stationary. After playing around with transformations, I found that if I took the difference and then subtracted the rolling average of seven values, I can get it stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtract_roll_mean(df, n=0): \n",
    "    roll_mean = df.rolling(window=n, center=False).mean()\n",
    "    sub_roll_mean = df - roll_mean\n",
    "    sub_roll_mean = sub_roll_mean\n",
    "    sub_roll_mean.columns = [\n",
    "        'Subtract Rolling Mean of ' + str(sub_roll_mean.columns[0])]\n",
    "\n",
    "    return sub_roll_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference(df):\n",
    "    diff_df = df.diff()\n",
    "    diff_df.columns = ['Annual Change of ' + str(df.columns[0])]\n",
    "    return diff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_data_t = model_data.copy()\n",
    "\n",
    "t = subtract_roll_mean(difference(model_data.iloc[:,0:1]), n=7)\n",
    "model_data_t.insert(1,t.columns[0],t)\n",
    "\n",
    "model_data_t.iloc[:,1:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before I move forward, I want to make sure I can transform this data back after modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inv_subtract_roll_mean(dfo,n=0, ex_copy = 0):\n",
    "    df = dfo.copy()\n",
    "\n",
    "    roll_sum = df.iloc[:,0:1].copy()\n",
    "    for i in range(n-1+ex_copy, len(df.iloc[:,0:1])):\n",
    "        roll_sum.iloc[i,0] = (n*df.iloc[i,1:3]+\n",
    "                              np.sum(np.sum(roll_sum.iloc[i-n+1:i,0])))/(n-1)\n",
    "\n",
    "    roll_sum.columns = ['Back Transformation of '+df.columns[1]]\n",
    "    \n",
    "    return roll_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inv_difference(df):\n",
    "    data = df.copy()\n",
    "    data['Back Transformation of ' + str(df.columns[1])] = np.nan\n",
    "    data.iloc[0,2:3] = data.iloc[0,0:1]\n",
    "    for i in range(1,len(df)):\n",
    "        data.iloc[i,2:3] = data.iloc[i-1,2:3].values[0]+ data.iloc[\n",
    "                                                            i,1:2].values[0]\n",
    "    return data.iloc[:,2:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def inv_diff_inv_sub(df, n=0):\n",
    "    # DataFrame, df, has the correct values on the left, and the transformed\n",
    "    # values on the right. The projected values are stacked on top of the\n",
    "    # transformed values, also on the right.\n",
    "    \n",
    "    test = df.copy()\n",
    "    t = difference(test.iloc[:,0:1])\n",
    "    test[str(t.columns[0])] = t\n",
    "    test = test.iloc[:,[0,2,1]]\n",
    "    t = inv_subtract_roll_mean(test.iloc[:,1:], n=n, ex_copy=1)\n",
    "    test[str(t.columns[0])] = t\n",
    "    t = inv_difference(test.iloc[:,[0,3]])\n",
    "    test[str(t.columns[0])] = t\n",
    "    test.rename(columns={test.iloc[:,4:5].columns[0]: \n",
    "        'Back Transformation of ' + df.iloc[:,1:2].columns[0]},inplace=1)\n",
    "\n",
    "    return test.iloc[:,4:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test = model_data_t.iloc[:,0:2].copy()\n",
    "test.iloc[:,1:2] = inv_diff_inv_sub(test, n=7)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transferring back is a possibility. Therefore, we can move forward. I'll again check for stationarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stationarity_check(model_data_t.iloc[:,1:2], s=56)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My p-value is .05. Stationarity achieved. I'll look at the decomposition graph again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "decomp_graph(model_data_t.iloc[:,1:2].dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like there's still a trend line, but it does pass stationarity, so I'm moving forward to the baseline random walk model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Walk Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_walk(df):\n",
    "    \n",
    "    # Create a series with the specified dates\n",
    "    # Need to drop any NaN terms.\n",
    "    first = df.dropna().copy()\n",
    "    skipped = len(df) - len(first)\n",
    "    dates_first = str(first.iloc[0:1,0:1].index[0])[:10]\n",
    "    dates_50 = pd.date_range(\"2022-01-01\", \"2051-01-01\", freq=\"AS\",\n",
    "                          inclusive=\"left\")\n",
    "\n",
    "    # White noise error term\n",
    "    # For standard devitaion, I took the standard deviation of the transformed\n",
    "    # data.\n",
    "    diff = df.diff().copy()\n",
    "    stnd_dev = np.std(df)[0]\n",
    "    error = np.random.normal(0, stnd_dev, len(dates_50))\n",
    "    \n",
    "    # Printing the calculated standard deviation.\n",
    "    print('Random Walk with Standard Deviation',\n",
    "          'of Transformed Data set: {:.2f}'.format(stnd_dev))\n",
    "    \n",
    "    #Starting point is the last transformed value.\n",
    "    Y_0 = df.iloc[-1,0:1].values[0]\n",
    "    cum_error = np.cumsum(error)\n",
    "    values = pd.DataFrame(cum_error + Y_0, index=dates_50)\n",
    "            \n",
    "    series = pd.DataFrame(values, index=dates_50)\n",
    "    series.columns = [df.columns[0] + ' -Random Walk Model']\n",
    "\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_formatting(df, y_hat, s):\n",
    "    # Showing IPCC targets if what is printed is Fossil Fuels\n",
    "    fossil = [' Gas ', ' Oil ', ' Coal ']\n",
    "    if (any([fuel in str(df.columns[0]) for fuel in fossil])) & (\n",
    "        any([str(df.columns[0]) in col for col in df_hist_elec.columns])):\n",
    "\n",
    "        goal = pd.concat([df,y_hat],axis=1).iloc[:,0:0]\n",
    "        goal['IPCC Emissions 2030 Reduction Goal'] = df.iloc[10,0]*.45\n",
    "        goal['IPCC Emissions 2050 Reduction Goal'] = 0\n",
    "        plt.plot(goal.iloc[10:31].index, goal.iloc[10:31,0:1].values, '--',\n",
    "                                                     label = goal.columns[0])\n",
    "        plt.plot(goal.iloc[30:51].index, goal.iloc[30:51,1:2].values, '--',\n",
    "                                                     label = goal.columns[1])\n",
    "    \n",
    "    # Plotting both historic and projected energy demand if the generation \n",
    "    # gets high enough to need the comparison.\n",
    "\n",
    "    if np.max([float(df.max()[0]), float(y_hat.max()[0])]) > 4000:\n",
    "\n",
    "        if df.columns[0][:6] == 'Europe':\n",
    "            c=7\n",
    "        else:\n",
    "            c=6\n",
    "        for i in range(len(df_proj_dem_stat.columns)):\n",
    "            if df_proj_dem_stat.columns[i][:c] in df.columns[0]:\n",
    "                dc = i\n",
    "                plt.plot(df_hist_dem.iloc[:,dc].index, df_hist_dem.iloc[:,dc],\n",
    "                   '--', label=str(df_hist_dem.iloc[:,dc:dc+1].columns[0])[s:])\n",
    "                plt.plot(df_proj_dem_stat.iloc[:,dc].index,\n",
    "                    df_proj_dem_stat.iloc[:,dc],\n",
    "                    '--', label=str(\n",
    "                    df_proj_dem_stat.iloc[:,dc:dc+1].columns[0])[s:])\n",
    "                break\n",
    "    \n",
    "    # Final Graph Formatting\n",
    "    plt.xlabel('Year', size = 15)\n",
    "    plt.ylabel('TWh', size = 15)\n",
    "    plt.xticks(size=15)\n",
    "    plt.yticks(size=15)\n",
    "    \n",
    "#    return goal, df_hist_dem, df_proj_dem_stat, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_graph(df, y_hat, s=0, title='col'):\n",
    "    \n",
    "    # Adding the end point of the original data to the y_hat DataFrame\n",
    "    y_hat.loc[df.index[-1], y_hat.columns] = df.iloc[-1,0]\n",
    "    y_hat.sort_index(inplace=True)\n",
    "    \n",
    "    fig = plt.figure(figsize = (10,6))\n",
    "    \n",
    "    # Plotting the historic and projected growth of the energy production.\n",
    "    \n",
    "    plt.plot(df.index, df.iloc[:,0], label=str(df.columns[0])[s:]+' -Historic')\n",
    "    \n",
    "    # In case the beginning of the column is \"Back Transformation of \" but the \n",
    "    # graph doesn't need that in the index label.\n",
    "    if s > 0:\n",
    "        if str(y_hat.columns[0])[:23] == 'Back Transformation of ':\n",
    "            ss = s+23\n",
    "        else:\n",
    "            ss = s+0\n",
    "    else:\n",
    "        ss = s+0\n",
    "            \n",
    "    plt.plot(y_hat.index, y_hat.iloc[:,0], label=str(y_hat.columns[0])[ss:])\n",
    "    \n",
    "    graph_formatting(df, y_hat, s)\n",
    "    \n",
    "    plt.legend(loc='best')\n",
    "    if title == 'col':\n",
    "        plt.title(y_hat.columns[0], size = 15)\n",
    "    else:\n",
    "        plt.title(title, size = 15)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows',None)\n",
    "y_hat_proj = random_walk(model_data_t.iloc[:,1:2])\n",
    "y_hat_proj.columns = [model_data.columns[0]+' -Random Walk Model']\n",
    "\n",
    "# Plot the transformed Random Walk\n",
    "pred_graph(model_data_t.iloc[:,1:2], y_hat_proj.iloc[:,0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Prepare the DataFrame for Back Transformation\n",
    "ranplot = model_data_t.iloc[:,0:2].copy()\n",
    "ranplot.rename(columns={str(ranplot.columns[1]): str(y_hat_proj.columns[0])},\n",
    "               inplace=True)\n",
    "ranplot = pd.concat([ranplot,y_hat_proj],axis=0)\n",
    "\n",
    "# Perform Back Transformation\n",
    "y_hat_proj = inv_diff_inv_sub(ranplot, n=7)\n",
    "\n",
    "#Plot the new graph\n",
    "pred_graph(model_data.iloc[:,0:1], y_hat_proj.iloc[22:,0:1], 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is as unreliable as it's name would imply, random walk. One of the things it relies on is a standard deviation of values. I decided to use the standard deviation of the data itself, but since it oscilates at a pretty clear pattern, up then down, at a pretty wide margin, the data of the random walk follows the same rises or falls, but because it is random, it spends too many cycles going up in a row or down in a row. This leads to most of the iterations of this model to outrageously high or low scores once the transformation is put back into place. Perhaps this is just a bad model for this? Perhaps I need to choose a different standard deviation? I spent a lot of time questioning this without getting any good answers.\n",
    "\n",
    "Now I'll move forward with an ARMA model. First, I need to evaluate the ACF and PACF plots to find the best Autoregressive and Moving Average terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Initial AR and MA Values with ACF and PACF Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ACF\n",
    "def plotacf(df, lags = 8):\n",
    "    df_diff = df.diff().dropna()\n",
    "    if len(df.columns) > 1:\n",
    "        for col in df_diff.columns:\n",
    "            fig, ax = plt.subplots(figsize=(8, 3))\n",
    "            plot_acf(df_diff[col], ax=ax, lags=lags);\n",
    "            plt.title('Autocorrelation for \\n' + col)\n",
    "            plt.ylabel('ACF', size = 15)\n",
    "    else:\n",
    "        fig, ax = plt.subplots(figsize=(8, 3))\n",
    "        plot_acf(df_diff, ax=ax, lags=lags);\n",
    "        plt.title('Autocorrelation for \\n' + df.columns[0])\n",
    "        plt.ylabel('ACF', size = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the PACF\n",
    "def plotpacf(df, lags = 8):\n",
    "    df_diff = df.diff().dropna()\n",
    "    if len(df.columns) > 1:\n",
    "        for col in df_diff.columns:\n",
    "            fig, ax = plt.subplots(figsize=(8, 3))\n",
    "            plot_pacf(df_diff[col], ax=ax, lags=lags, method=\"ywm\");\n",
    "            plt.title('Partial Autocorrelation for \\n' + col)\n",
    "            plt.ylabel('PACF', size = 15)\n",
    "\n",
    "    else:\n",
    "        fig, ax = plt.subplots(figsize=(8, 3))\n",
    "        plot_pacf(df_diff, ax=ax, lags=lags, method=\"ywm\");\n",
    "        plt.title('Partial Autocorrelation for \\n' + df.columns[0])\n",
    "        plt.ylabel('PACF', size = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotacf(model_data_t.iloc[:,1:2], lags = 6)\n",
    "plotpacf(model_data_t.iloc[:,1:2], lags = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have a breach of the confidence interval on the PACF at 2, that means that, for the baseline model, the Autoregressive term, AR, should be 2, while the other terms are 0. Now to create the first ARMA model with (2,0,0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARMA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_print(mod_lst):\n",
    "    asterisks = ('****************************************' + \n",
    "                '***************************************')\n",
    "    if str(type(mod_lst)) != list:\n",
    "        print(asterisks)\n",
    "        print(mod_lst.name, 'model results.')\n",
    "        print()\n",
    "        print(mod_lst.summary())\n",
    "        return\n",
    "    for mod in mod_lst:\n",
    "        print(asterisks)\n",
    "        print(mod.name, 'model results.')\n",
    "        print()\n",
    "        print(mod.summary())\n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_transformation(df, y_hat, st, en, transformation, n=0):\n",
    "    df_copy = df.copy()\n",
    "    df_copy.columns = [df_copy.columns[0], y_hat.columns[0]]\n",
    "    # Check if this run is modeling future data\n",
    "    if y_hat.index[-1] > df_copy.index[-1]:\n",
    "        pred_p = df_copy.iloc[:,1:2].append(y_hat.iloc[1:,:])\n",
    "        pred_p = pd.concat([df_copy.iloc[:,0:1],pred_p], axis=1)\n",
    "    # Modeling the given data to check RMSE\n",
    "    else:\n",
    "        pred_p = pd.concat([df_copy.iloc[:,0:1],y_hat.iloc[:,0:1]],axis=1)\n",
    "    \n",
    "    # Performing the transformation\n",
    "    if transformation == 'inv_diff_inv_sub':\n",
    "        pred = inv_diff_inv_sub(pred_p, n)\n",
    "    if transformation == 'inv_log_inv_sub':\n",
    "        pred = inv_log_inv_sub(pred_p, n)\n",
    "    if transformation == 'inv_subtract_roll_mean':\n",
    "        pred = inv_subtract_roll_mean(pred_p, n)\n",
    "    if transformation == 'inv_difference':\n",
    "        pred = inv_difference(pred_p)\n",
    "    if transformation == 'inv_log_transform':\n",
    "        pred = inv_difference(pred_p)\n",
    "    \n",
    "    # To check if the given data was back transformed correctly.\n",
    "    df_bt = pred.iloc[:len(df_copy),0:1]\n",
    "    df_bt.rename(columns={df_bt.iloc[:,0:1].columns[0]: \n",
    "        'Back Transformation of ' + df.iloc[:,0:1].columns[0]},inplace=1)\n",
    "    \n",
    "    # Creating the back transformed prediction\n",
    "    y_hat_bt = pred.iloc[st:,0:1]\n",
    "    \n",
    "    return df_bt, y_hat_bt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mod_pred(df, o, st, en, message='n', tran=None, n=0):\n",
    "    \n",
    "    # For dataFrames with fewer layers.\n",
    "    l = len(df.columns)\n",
    "    \n",
    "    # Fitting the Model\n",
    "    mod_arima = ARIMA(df.iloc[:,l-1:l], order = o)\n",
    "    fit_arima = mod_arima.fit()\n",
    "    fit_arima.name = df.columns[0]\n",
    "    \n",
    "    # Predicting the specified timeline.\n",
    "    y_hat_t = pd.DataFrame(fit_arima.predict(start = st-1, end = en))\n",
    "    y_hat_t.columns = [df.columns[0] + ' -ARIMA Prediction ' + str(o) + \n",
    "                       ' On Transformation']\n",
    "    \n",
    "    # Predicting the original DataFrame\n",
    "    y_hat_org = pd.DataFrame(fit_arima.predict(start = 0, end = len(df)-1))\n",
    "    \n",
    "    df_bt = None\n",
    "    y_hat_bt = None\n",
    "    y_hat_org_bt = None\n",
    "    \n",
    "    if tran != None:\n",
    "        df_bt, y_hat_bt = back_transformation(df, y_hat_t, st, en, tran, n)\n",
    "\n",
    "        df_bt_jnk, y_hat_org_bt = back_transformation(df, y_hat_org, 0,\n",
    "                                                  len(df)-1, tran, n)\n",
    "\n",
    "        rmse, aic = mod_stats(fit_arima, df.iloc[:,0:1], y_hat_org_bt, \n",
    "                              message = message, o = o, n=n)\n",
    "        y_hat_org_bt.columns = [str(df.columns[0])+\n",
    "                            ' -ARIMA Prediction '+str(o)+' on Original']\n",
    "        y_hat_org.columns =    [str(df.columns[0])+\n",
    "                            ' -ARIMA Prediction '+str(o)+' on Transformation']\n",
    "    else:\n",
    "        rmse, aic = mod_stats(fit_arima, df.iloc[:,0:1], y_hat_org,\n",
    "                              message = message, o = o)\n",
    "        y_hat_org.columns =    [str(df.columns[0])+\n",
    "                            ' -ARIMA Prediction '+str(o)+' on Original']\n",
    "        y_hat_org_bt = y_hat_org.copy()\n",
    "    \n",
    "    return fit_arima, y_hat_t, rmse, aic, df_bt, y_hat_bt, y_hat_org_bt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mod_pred_s(df, o, st, en, message='n', tran=None, n=0):\n",
    "    fit_arima, y_hat_t, rmse, aic, df_bt, y_hat_bt, y_hat_org_bt = mod_pred(df,\n",
    "                                o, st, en, message=message, tran=tran, n=n)\n",
    "    \n",
    "    return y_hat_t, y_hat_org_bt, y_hat_bt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mod_stats(mod, df, y_hat, message='n', o=None, n=0):\n",
    "    rmse = sk.metrics.mean_squared_error(df.iloc[n:], y_hat.iloc[n:],\n",
    "                                         squared = False)\n",
    "    mod_aic = mod.aic\n",
    "    if message == 'y':\n",
    "        print()\n",
    "        print('ARIMA: {}'.format(o) + ', RMSE={:.2f}, AIC={:.2f}'.format(rmse,\n",
    "                                                                    mod_aic))\n",
    "    return rmse, mod_aic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def model_summary(df, o, st, en, s=0, tran=None, n=0):\n",
    "    l = len(df.columns)\n",
    "\n",
    "    model, y_hat_t, rmse, mod_aic, df_bt, y_hat_bt, y_hat_org_bt = mod_pred(df,\n",
    "                                 o, st, en, message = 'y', tran=tran, n=n)\n",
    "\n",
    "    summary_print(model)\n",
    "\n",
    "    pred_graph(df.iloc[:,l-1:l], y_hat_t, 0)\n",
    "    \n",
    "    # There's no standard starting point for the original data projection since\n",
    "    # some models start their projection after a specific number of copies of\n",
    "    # the original data. To make this look nicer in the graph, I wrote this \n",
    "    # for loop. It will determine where to start if the model copies the first\n",
    "    # few values.\n",
    "    b_num = n\n",
    "    for i in range(1,len(y_hat_org_bt)):\n",
    "        # Rounding the values to add a small degree of uncertainty.\n",
    "        y_hat_org_bt_point = round(y_hat_org_bt.iloc[i,0:1].values[0],1)\n",
    "        df_point = round(df.iloc[i,0:1].values[0],1)\n",
    "        if y_hat_org_bt_point != df_point:\n",
    "            break\n",
    "        else:\n",
    "            b_num -= 1\n",
    "        \n",
    "    # Printing a comparison of the original data and the prediction of the same\n",
    "    # time period back transformed. This graph visualizes the data used to \n",
    "    # calculate the RMSE score.\n",
    "    pred_graph(df.iloc[:,0:1], y_hat_org_bt.iloc[n-b_num:,:], s)\n",
    "\n",
    "    # Printing the original data with the projected back transformed data.\n",
    "    # If there is no transformation, y_hat_bt is still the value used to \n",
    "    # produce this graph. \n",
    "    pred_graph(df.iloc[:,0:1], y_hat_bt, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows',60)\n",
    "order = (2,0,0)\n",
    "model_summary(model_data_t.iloc[:,0:2], order, 22, 50, 14,\n",
    "          tran = 'inv_diff_inv_sub', n=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model looks very promising, but I want to test it through a grid search through the ARIMA models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA Model and Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def arima_pdq(df, st = 22, en = 50, s=0, tran=None, n=0):\n",
    "    title = df.columns[0]\n",
    "    \n",
    "    # Initial Parameters\n",
    "    best_rmse =  5000000000000000000000000\n",
    "    best_aic = 5000000000000000000000000\n",
    "    \n",
    "    # I tried several iterations of the CV grid search. These were the maximum\n",
    "    # parameters that yeilded good results. \n",
    "    p_val = range(0,9)\n",
    "    d_val = range(0,2)\n",
    "    q_val = range(0,8)\n",
    "\n",
    "    for p in p_val:\n",
    "        for d in d_val:\n",
    "            for q in q_val:\n",
    "                try:\n",
    "                    order = (p, d, q)\n",
    "                    model, yht, rmse, aic, df_bt, y_hat_bt, yho = mod_pred(df,\n",
    "                                         order, 22, 50, tran=tran, n=n)\n",
    "                    \n",
    "                    # Removing spurious results\n",
    "                    if abs(y_hat_bt.iloc[-1].values[0]) > 10000:\n",
    "                        continue\n",
    "                        \n",
    "                    if rmse < best_rmse:\n",
    "                        best_rmse = rmse\n",
    "                        best_rmse, rmse_aic, rmse_cfg = rmse, aic, order\n",
    "                        rmse_2050 = y_hat_bt.iloc[-1].values[0]\n",
    "                        print('RMSE ARIMA: {}, RMSE= {:.2f},'.format(rmse_cfg,\n",
    "                                                                best_rmse),\n",
    "                              'AIC= {:.2f}, TWh-2050= {:.2f}'.format(rmse_aic,\n",
    "                                                            rmse_2050))\n",
    "                    if aic < best_aic:\n",
    "                        best_aic = aic\n",
    "                        aic_rmse, best_aic, aic_cfg = rmse, aic, order\n",
    "                        aic_2050 = y_hat_bt.iloc[-1].values[0]\n",
    "                        if order == rmse_cfg:\n",
    "                            continue\n",
    "                        print('AIC  ARIMA: {}, RMSE= {:.2f},'.format(aic_cfg,\n",
    "                                                                aic_rmse),\n",
    "                              'AIC= {:.2f}, TWh-2050= {:.2f}'.format(best_aic,\n",
    "                                                            aic_2050))\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "    print('Best RMSE ARIMA: {} RMSE= {:.2f}'.format(rmse_cfg, best_rmse),\n",
    "         'AIC= {:.2f}, TWh-2050= {:.2f}'.format(rmse_aic, rmse_2050))\n",
    "    print('Best AIC  ARIMA: {} RMSE= {:.2f}'.format(aic_cfg, aic_rmse),\n",
    "         'AIC= {:.2f}, TWh-2050= {:.2f}'.format(best_aic, aic_2050))\n",
    "\n",
    "    yh_t_rmse, yh_rmse_org_bt, yh_rmse = mod_pred_s(df, rmse_cfg, 22, 50,\n",
    "                                                tran=tran, n=n)\n",
    "\n",
    "    yh_t_aic,  yh_aic_org_bt,  yh_aic  = mod_pred_s(df, aic_cfg,  22, 50,\n",
    "                                                tran=tran, n=n)\n",
    "    \n",
    "    \n",
    "    yh_rmse.columns = ['Prediction']\n",
    "    yh_aic.columns = ['Prediction']\n",
    "    yh_rmse_org_bt.columns = [(df.columns[0] + ' -Transformed\\nARIMA Best RMSE '+\n",
    "                      str(rmse_cfg)  + ' -Test Projection')]\n",
    "    yh_aic_org_bt.columns = [(df.columns[0] + ' -Transformed\\nARIMA Best AIC '+\n",
    "                      str(aic_cfg)  + ' -Test Projection')]\n",
    "\n",
    "    # Setting the first point in the prediction df to the same value as\n",
    "    # the last point in the historic df.\n",
    "    yh_rmse.loc[df.index[-1], yh_rmse.columns] = df.iloc[-1,0].copy()\n",
    "    yh_aic.loc[df.index[-1], yh_aic.columns] = df.iloc[-1,0].copy()\n",
    "\n",
    "    # Sorting index\n",
    "    yh_rmse.sort_index(inplace=True)\n",
    "    yh_aic.sort_index(inplace=True)\n",
    "    df.sort_index(inplace=True)\n",
    "\n",
    "    # Plotting figure\n",
    "    fig = plt.figure(figsize = (10,6))\n",
    "    \n",
    "    # Original Data\n",
    "    plt.plot(df.index, df.iloc[:,0], label=str(df.columns[0])[s:]+' -Historic')\n",
    "    \n",
    "    # Projection from start to end date\n",
    "    plt.plot(yh_rmse.index, yh_rmse.iloc[:,0], \n",
    "             label=str(df.columns[0])[s:]+' -ARIMA Best RMSE ' + str(rmse_cfg))\n",
    "    plt.plot(yh_aic.index, yh_aic.iloc[:,0], \n",
    "             label=str(df.columns[0])[s:]+' -ARIMA Best AIC ' + str(aic_cfg))\n",
    "        \n",
    "    # Formatting the graph and printing the goal lines \n",
    "    if True:\n",
    "        graph_formatting(df.iloc[:,0:1], yh_rmse.iloc[:,0:1], s)\n",
    "    #except:\n",
    "        print('Graph_formatting produced error at',\n",
    "              str(rmse_cfg) , 'or', str(aic_cfg))\n",
    "        \n",
    "    plt.legend(loc='best')\n",
    "    plt.title(title + \" -ARIMA Forecast\", size=15)\n",
    "    plt.show()\n",
    "    \n",
    "    # Plotting Transformed Figures for both estimates and test plots.\n",
    "    title_rmse =      (df.columns[0] + ' -Transformed\\nARIMA Best RMSE '+\n",
    "                      str(rmse_cfg))\n",
    "    title_rmse_test = (df.columns[0] + ' -Transformed\\nARIMA Best RMSE '+\n",
    "                      str(rmse_cfg)  + ' -Test Projection')\n",
    "    title_aic =       (df.columns[0] + ' -Transformed\\nARIMA Best AIC '+\n",
    "                      str(aic_cfg))\n",
    "    title_aic_test =  (df.columns[0] + ' -Transformed\\nARIMA Best AIC '+\n",
    "                      str(aic_cfg)  + ' -Test Projection')\n",
    "    pred_graph(df.iloc[:,1:2], yh_t_rmse,  title=title_rmse)\n",
    "    pred_graph(df.iloc[:,0:1], yh_rmse_org_bt, title=title_rmse_test)\n",
    "    pred_graph(df.iloc[:,1:2], yh_t_aic,   title=title_aic)\n",
    "    pred_graph(df.iloc[:,0:1], yh_aic_org_bt,  title=title_aic_test)\n",
    "    \n",
    "    \n",
    "    return rmse_cfg, aic_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "coal_rmse_cfg, coal_aic_cfg = arima_pdq(\n",
    "                model_data_t.iloc[:,0:2], s=14, tran = 'inv_diff_inv_sub', n=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm not sure I like either of these graphs as much as I the original, order (2,0,0). It just looks like a much better progression and estimate for how things will go. Regardless, one thing I like is that coal is going down and will likely not be used in a little more than a decade. Here's to hoping that trend will continue.\n",
    "\n",
    "Also, all the models show that the United States will meet its reduction in coal use by 2030. That's also great news.\n",
    "\n",
    "For Coal, the best pdq is (5, 5, 4)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA Without Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def arima_pdq_no_tran(df, st, en, s=0):\n",
    "    title = df.columns[0]\n",
    "    print(title, 'Grid Search:')\n",
    "    \n",
    "    # Initial Parameters\n",
    "    best_rmse =  5000000000000000000000000\n",
    "    best_aic = 5000000000000000000000000\n",
    "\n",
    "    # I tried several iterations of the CV grid search. These were the maximum\n",
    "    # parameters that yeilded good results. \n",
    "    p_val = range(0,9)\n",
    "    d_val = range(0,4)\n",
    "    q_val = range(0,9)\n",
    "\n",
    "    for p in p_val:\n",
    "        for d in d_val:\n",
    "            for q in q_val:\n",
    "                try:\n",
    "                    order = (p, d, q)\n",
    "                    # Build the model\n",
    "                    model = ARIMA(df, order=order).fit()\n",
    "                    \n",
    "                    # Build prediction of given data\n",
    "                    y_hat_org = model.predict(start=0, end=(len(df)-1))\n",
    "                    \n",
    "                    # Build projection\n",
    "                    y_hat = model.predict(start=st, end=en)\n",
    "                    \n",
    "                    # Removing spurious results\n",
    "                    if abs(y_hat.iloc[-1]) > 10000:\n",
    "                        continue\n",
    "                        \n",
    "                    # Make the first and last point of original prediction the\n",
    "                    # same as the first point in the dataset to not throw off\n",
    "                    # the rmse score\n",
    "                    y_hat_org[0] =  df.iloc[0,0:1].values[0]\n",
    "                    y_hat_org[-1] = df.iloc[-1,0:1].values[0]\n",
    "                    \n",
    "                    # Take measurements\n",
    "                    rmse = sk.metrics.mean_squared_error(\n",
    "                        df, y_hat_org, squared = False)\n",
    "                    aic  = model.aic\n",
    "                    \n",
    "                    if rmse < best_rmse:\n",
    "                        best_rmse = rmse\n",
    "                        rmse_aic, rmse_cfg = aic, order\n",
    "                        rmse_2050 = y_hat.iloc[-1]\n",
    "                        print('RMSE ARIMA: {}, RMSE= {:.2f},'.format(rmse_cfg,\n",
    "                                                                best_rmse),\n",
    "                              'AIC= {:.2f}, TWh-2050= {:.2f}'.format(rmse_aic,\n",
    "                                                            rmse_2050))\n",
    "                    if aic < best_aic:\n",
    "                        best_aic = aic\n",
    "                        aic_rmse, aic_cfg = rmse, order\n",
    "                        aic_2050 = y_hat.iloc[-1]\n",
    "                        if order == rmse_cfg:\n",
    "                            continue\n",
    "                        print('AIC  ARIMA: {}, RMSE= {:.2f},'.format(aic_cfg,\n",
    "                                                                aic_rmse),\n",
    "                              'AIC= {:.2f}, TWh-2050= {:.2f}'.format(best_aic,\n",
    "                                                            aic_2050))\n",
    "                except:\n",
    "                    continue\n",
    "    print('Best RMSE ARIMA: {} RMSE= {:.2f}'.format(rmse_cfg, best_rmse),\n",
    "         'AIC= {:.2f}, TWh-2050= {:.2f}'.format(rmse_aic, rmse_2050))\n",
    "    print('Best AIC  ARIMA: {} RMSE= {:.2f}'.format(aic_cfg, aic_rmse),\n",
    "         'AIC= {:.2f}, TWh-2050= {:.2f}'.format(best_aic, aic_2050))\n",
    "\n",
    "    # Creating final model, predictions and projection over given data \n",
    "    mod_rmse = ARIMA(df, order = rmse_cfg).fit()\n",
    "    yh_rmse = pd.DataFrame(mod_rmse.predict(st, en))\n",
    "    yh_rmse_org = pd.DataFrame(mod_rmse.predict(0, len(df)-1))\n",
    "    yh_rmse.columns = ['Prediction']\n",
    "    yh_rmse_org.columns = [(df.columns[0] + ' -Transformed\\nARIMA Best RMSE '+\n",
    "                      str(rmse_cfg)  + ' -Test Projection')]\n",
    "    \n",
    "    mod_aic = ARIMA(df, order = aic_cfg).fit()\n",
    "    yh_aic = pd.DataFrame(mod_aic.predict(st, en))\n",
    "    yh_aic_org = pd.DataFrame(mod_aic.predict(0, len(df)-1))\n",
    "    yh_aic.columns = ['Prediction']\n",
    "    yh_aic_org.columns = [(df.columns[0] + ' -Transformed\\nARIMA Best AIC '+\n",
    "                      str(aic_cfg)  + ' -Test Projection')]\n",
    "    \n",
    "    # Setting the first point in the prediction df to the same value as\n",
    "    # the last point in the historic df.\n",
    "    yh_rmse.loc[df.index[-1], yh_rmse.columns] = df.iloc[-1,0].copy()\n",
    "    yh_aic.loc[df.index[-1], yh_aic.columns] = df.iloc[-1,0].copy()\n",
    "    \n",
    "    # Setting first point of the projection over given data to visually check\n",
    "    # what was calculated for the RMSE score.\n",
    "    yh_rmse_org.iloc[0,0:1]  = df.iloc[0,0:1].values[0]\n",
    "#    yh_rmse_org.iloc[-1,0:1] = df.iloc[-1,0:1].values[0]\n",
    "    yh_aic_org.iloc[0,0:1]   = df.iloc[0,0:1].values[0]\n",
    "#    yh_aic_org.iloc[-1,0:1]  = df.iloc[-1,0:1].values[0]\n",
    "    \n",
    "    # Sorting index\n",
    "    yh_rmse.sort_index(inplace=True)\n",
    "    yh_aic.sort_index(inplace=True)\n",
    "    df.sort_index(inplace=True)\n",
    "\n",
    "    # Plotting figure\n",
    "    fig = plt.figure(figsize = (10,6))\n",
    "    plt.plot(df.index, df.iloc[:,0], label=str(df.columns[0])[s:]+' -Historic')\n",
    "    plt.plot(yh_rmse.index, yh_rmse.iloc[:,0], \n",
    "             label=str(df.columns[0])[s:]+' -ARIMA Best RMSE ' + str(rmse_cfg))\n",
    "    plt.plot(yh_aic.index, yh_aic.iloc[:,0], \n",
    "             label=str(df.columns[0])[s:]+' -ARIMA Best AIC ' + str(aic_cfg))\n",
    "    plt.legend(loc='best')\n",
    "    plt.title(title + \" ARIMA Forecast\")\n",
    "    \n",
    "    try:\n",
    "        graph_formatting(df.iloc[:,0:1], yh_rmse.iloc[:,0:1], s)\n",
    "    except:\n",
    "        print('Graph_formatting produced error at',\n",
    "              str(rmse_cfg) , 'or', str(aic_cfg))\n",
    "    \n",
    "    plt.legend(loc='best')\n",
    "    plt.title(title + \" ARIMA Forecast\", size = 15)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    # Plotting projection over given data, the test plot..\n",
    "    title_rmse_test = (df.columns[0] + ' -Transformed\\nARIMA Best RMSE '+\n",
    "                      str(rmse_cfg)  + ' -Test Projection')\n",
    "    title_aic_test =  (df.columns[0] + ' -Transformed\\nARIMA Best AIC '+\n",
    "                      str(aic_cfg)  + ' -Test Projection')\n",
    "    pred_graph(df.iloc[:,0:1], yh_rmse_org, title=title_rmse_test)\n",
    "    pred_graph(df.iloc[:,0:1], yh_aic_org,  title=title_aic_test)    \n",
    "    \n",
    "    return rmse_cfg, aic_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arima_no_tran(df, o, st, en, s=0):\n",
    "    model = ARIMA(df, order=o).fit()\n",
    "    y_hat_org = model.predict(start=0, end=(len(df)-1))\n",
    "    y_hat = model.predict(start=st, end=en)\n",
    "    \n",
    "    # Adding the end point of the original data to the y_hat DataFrame\n",
    "    y_hat = pd.DataFrame(y_hat)    \n",
    "    y_hat.loc[df.index[-1], y_hat.columns] = df.iloc[-1,0]\n",
    "    y_hat.sort_index(inplace=True)\n",
    "    \n",
    "    # Setting the first point of the original prediction to the same as the \n",
    "    # last point of data to not throw off the RMSE\n",
    "    y_hat_org[0] = df.iloc[0,0:1].values[0]\n",
    "    \n",
    "    # Creating DataFrames for the y-hats\n",
    "    y_hat_org = pd.DataFrame(y_hat_org)\n",
    "\n",
    "    model.name = df.columns[0] + ' -ARIMA Prediction '+str(o)\n",
    "    \n",
    "    # Setting Column names for y-hat\n",
    "    y_hat_org.columns = [(df.columns[0] + ' ARIMA Prediction '+str(o) + \n",
    "                         '\\nPrediction on Original Data')]\n",
    "    \n",
    "    y_hat.columns =  [df.columns[0] + ' ARIMA Prediction '+str(o)]\n",
    "    \n",
    "    return model, y_hat, y_hat_org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def model_summary_no_tran(df, o, st, en, s=0):\n",
    "    model, y_hat, y_hat_org = arima_no_tran(df, o, st, en, s=s)\n",
    "    \n",
    "    # Calculate the RMSE & AIC\n",
    "    rmse = sk.metrics.mean_squared_error(\n",
    "                        df, y_hat_org, squared = False)\n",
    "    aic  = model.aic\n",
    "\n",
    "    print()\n",
    "    print('ARIMA: {}'.format(o) + ', RMSE={:.2f}, AIC={:.2f}'.format(rmse,\n",
    "                                                                    aic))\n",
    "    summary_print(model)\n",
    "    \n",
    "    pred_graph(df.iloc[:,0:1], y_hat.iloc[:,0:1], s)\n",
    "    pred_graph(df, y_hat_org, s)\n",
    "    \n",
    "    \n",
    "    return y_hat, y_hat_org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "coal_rmse_cfg, coal_aic_cfg = arima_pdq_no_tran(model_data.iloc[:,0:1], 22, 50, s=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_coal = model_data_t.iloc[:,0:1]\n",
    "\n",
    "#                   Model,   df_o,     pdq,    tran, n, PDQs\n",
    "selected_models = [['ARIMA', df_coal, (5,1,3), None, 0, None]]\n",
    "\n",
    "m = 0\n",
    "model_summary_no_tran(selected_models[m][1], selected_models[m][2], 22, 50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is a good mix of decent RMSE for this scale and likely behavior of energy production. The AIC is not the best, but, for this energy source, the models with good AIC do not give realistic results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gas\n",
    "### Distribution Investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stored_model_data = model_data.copy()\n",
    "stored_model_data_t = model_data_t.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = stored_model_data.copy()\n",
    "model_data_t = stored_model_data_t.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hist(model_data.iloc[:,1:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_block = s_block(model_data.iloc[:,1:2], stats_block)\n",
    "stats_block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A somewhat of symmetrical distribution with flat tails. It's skewed positively slightly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposing The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomp_graph(model_data.iloc[:,1:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No seasonality or residuals. I'll check for stationarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for Stationarity and Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 30)\n",
    "stationarity_check(model_data.iloc[:,1:2], s=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not close to stationary. After playing around with transformations, I found that if I took the log and then subtracted the rolling average of four values, I can get it stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_transform(df):\n",
    "    df_np = df.iloc[:,0:1].values[:,0]\n",
    "    logged_df = pd.DataFrame(np.log(df_np), index = df.index, \n",
    "                             columns = 'Natural Logged ' + df.columns)\n",
    "\n",
    "    return logged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t = subtract_roll_mean(log_transform(model_data.iloc[:,1:2]), n=4)\n",
    "model_data_t.insert(3,t.columns[0],t)\n",
    "\n",
    "model_data_t.iloc[:,2:4].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before I move forward, I want to make sure I can transform this data back after modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inv_log_transform(df):\n",
    "    l = len(df.columns)\n",
    "    df_np = df.iloc[:,l-1:l].values[:,0]\n",
    "\n",
    "    exp_df = pd.DataFrame(np.exp(df_np), index = df.index, \n",
    "                        columns = ['Back Transformation of ' + df.columns[0]])\n",
    "\n",
    "    return exp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inv_log_inv_sub(df, n=0):\n",
    "    test = df.copy()\n",
    "    t = log_transform(test.iloc[:,0:1])\n",
    "    test[str(t.columns[0])] = t\n",
    "    test = test.iloc[:,[0,2,1]]\n",
    "    t = inv_subtract_roll_mean(test.iloc[:,1:], n=n, ex_copy=1)\n",
    "    test[str(t.columns[0])] = t\n",
    "    t = inv_log_transform(test.iloc[:,[0,3]])\n",
    "    test[str(t.columns[0])] = t\n",
    "    test.rename(columns={test.iloc[:,4:5].columns[0]:\n",
    "            'Back Transformation of ' + df.iloc[:,1:2].columns[0]},inplace=1)\n",
    "\n",
    "    return test.iloc[:,4:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test = model_data_t.iloc[:,2:4].copy()\n",
    "\n",
    "test['Results'] = inv_log_inv_sub(test,n=4)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transferring back is a possibility. Therefore, I can move forward. I'll again check for stationarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stationarity_check(model_data_t.iloc[:,3:4], s=54)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My p-value is less than .05. Stationarity achieved. I'll look at the decomposition graph again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "decomp_graph(model_data_t.iloc[:,3:4].dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like there's still a trend line, but it does pass stationarity, so I'm moving forward to the baseline random walk model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Walk Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows',None)\n",
    "y_hat_proj = random_walk(model_data_t.iloc[:,3:4])\n",
    "y_hat_proj.columns = [model_data.columns[1]+' -Random Walk Model']\n",
    "\n",
    "# Plot the transformed Random Walk\n",
    "pred_graph(model_data_t.iloc[:,3:4], y_hat_proj.iloc[:,0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the DataFrame for Back Transformation\n",
    "ranplot = model_data_t.iloc[:,2:4].copy()\n",
    "ranplot.rename(columns={str(ranplot.columns[1]): str(y_hat_proj.columns[0])},\n",
    "               inplace=True)\n",
    "\n",
    "ranplot = pd.concat([ranplot,y_hat_proj],axis=0)\n",
    "\n",
    "# Perform Back Transformation\n",
    "y_hat_proj = inv_log_inv_sub(ranplot, n=4)\n",
    "\n",
    "#Plot the new graph\n",
    "pred_graph(model_data_t.iloc[:,2:3], y_hat_proj.iloc[22:,0:1], 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is as unreliable as it's name would imply, random walk. This one performs better in part because of a much smaller standard deviation for the dataset, and the transformation doesn't affect it nearly as strong. This one is ok.\n",
    "\n",
    "Now I'll move forward with an ARMA model. First, I need to evaluate the ACF and PACF plots to find the best Autoregressive and Moving Average terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Initial AR and MA Values with ACF and PACF Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotacf(model_data_t.iloc[:,3:4], lags = 6)\n",
    "plotpacf(model_data_t.iloc[:,3:4], lags = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ACF is awfully close to breaching at 2, and PACF definitely breaches at two. I will try both (2,0,0) and (2,0,2) for my initial ARMA models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARMA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows',60)\n",
    "order = (2,0,0)\n",
    "model_summary(model_data_t.iloc[:,2:4], order, 22, 50, 14,\n",
    "          tran = 'inv_log_inv_sub', n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows',60)\n",
    "order = (2,0,2)\n",
    "model_summary(model_data_t.iloc[:,2:4], order, 22, 50, 0,\n",
    "          tran = 'inv_log_inv_sub', n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to both models, Gas will overtake our entire electricity demand before 2050. I find this plausible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA Model and Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gas_rmse_cfg, gas_aic_cfg = arima_pdq(\n",
    "                model_data_t.iloc[:,2:4], s=14, tran = 'inv_log_inv_sub', n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This predicts that gas will be on an exponential curve, which I think is more realistic than I'd like to admit. I think these models are the best I've got. I'll still try it without transformations though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA Without Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gas_rmse_cfg, gas_aic_cfg = arima_pdq_no_tran(\n",
    "                                        model_data.iloc[:,1:2], 22, 50, s=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deleteme\n",
    "stored_gas = selected_models.copy()\n",
    "selected_models = stored_gas.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "selected_models = stored_gas.copy()\n",
    "df_gas = model_data_t.iloc[:,2:3]\n",
    "\n",
    "#                        Model,  df_o,   pdq,     tran, n, PDQs\n",
    "selected_models.append(['ARIMA', df_gas, (3,1,8), None, 0, None])\n",
    "\n",
    "m = 1\n",
    "model_summary_no_tran(selected_models[m][1], selected_models[m][2], 22, 50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models produced by the transformation model all show a shockingly high rate of natural gas into the future. Nearly all of the predict natural gas could be used as our sole power source by 2050. There are many reasons that is unlikely.\n",
    "\n",
    "The non-transformation model still shows a steady incline in natural gas, and predicts about half our energy use by 2050 will be natural gas. This is much more reasonable. The RMSE difference between the two (49.56 and 37.63) is less than 15. I'll select the non-transformation model for this source. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oil\n",
    "### Distribution Investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stored_model_data = model_data.copy()\n",
    "stored_model_data_t = model_data_t.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = stored_model_data.copy()\n",
    "model_data_t = stored_model_data_t.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hist(model_data.iloc[:,2:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_block = s_block(model_data.iloc[:,2:3], stats_block)\n",
    "stats_block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has a positive skew distribution with wide and flat tails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposing The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomp_graph(model_data.iloc[:,2:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No seasonality or residuals. I'll check for stationarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for Stationarity and Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 30)\n",
    "stationarity_check(model_data.iloc[:,2:3], s=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not close to stationary. After playing around with transformations, I found that if I took the difference of values, I can get it stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t = difference(model_data.iloc[:,2:3])\n",
    "model_data_t.insert(5,t.columns[0],t)\n",
    "\n",
    "model_data_t.iloc[:,4:6].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before I move forward, I want to make sure I can transform this data back after modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test = model_data_t.iloc[:,4:6].copy()\n",
    "\n",
    "test['Results'] = inv_difference(test)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transferring back is a possibility. Therefore, I can move forward. I'll again check for stationarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stationarity_check(model_data_t.iloc[:,5:6], s=31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My p-value is .05. Stationarity achieved. I'll look at the decomposition graph again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "decomp_graph(model_data_t.iloc[:,5:6].dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like there's still a trend line, but it does pass stationarity, so I'm moving forward to the baseline random walk model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Walk Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows',None)\n",
    "y_hat_proj = random_walk(model_data_t.iloc[:,5:6])\n",
    "y_hat_proj.columns = [model_data.columns[2]+' -Random Walk Model']\n",
    "\n",
    "# Plot the transformed Random Walk\n",
    "pred_graph(model_data_t.iloc[:,5:6], y_hat_proj.iloc[:,0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the DataFrame for Back Transformation\n",
    "ranplot = model_data_t.iloc[:,4:6].copy()\n",
    "ranplot.rename(columns={str(ranplot.columns[1]): str(y_hat_proj.columns[0])},\n",
    "               inplace=True)\n",
    "\n",
    "ranplot = pd.concat([ranplot,y_hat_proj],axis=0)\n",
    "\n",
    "# Perform Back Transformation\n",
    "y_hat_proj = inv_difference(ranplot)\n",
    "\n",
    "#Plot the new graph\n",
    "pred_graph(model_data_t.iloc[:,4:5], y_hat_proj.iloc[22:,0:1], 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is as unreliable as it's name would imply, random walk. I think any of these random walks that oscillate about zero in transformed state are going to appear really strange after transformed back.\n",
    "\n",
    "Now I'll move forward with an ARMA model. First, I need to evaluate the ACF and PACF plots to find the best Autoregressive and Moving Average terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Initial AR and MA Values with ACF and PACF Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotacf(model_data_t.iloc[:,5:6], lags = 6)\n",
    "plotpacf(model_data_t.iloc[:,5:6], lags = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ACF breaches at 1, and PACF definitely breaches at 1 and 3. I will try both (1,0,1) and (3,0,1) for my initial ARMA models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARMA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "order = (1,0,1)\n",
    "model_summary(model_data_t.iloc[:,4:6], order, 22, 50, 14,\n",
    "          tran = 'inv_difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "order = (3,0,1)\n",
    "model_summary(model_data_t.iloc[:,4:6], order, 22, 50, 0,\n",
    "          tran = 'inv_difference')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These models both look convincing. Oil as a power source for electricity is on its way out. As always, I'll see what the grid search says."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA Model and Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "oil_rmse_cfg, oil_aic_cfg = arima_pdq(\n",
    "                model_data_t.iloc[:,4:6], s=14, tran = 'inv_difference')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks as though Coal is declining so quick, it may be gone by 2040. Also, it has nearly already hit the 2030 IPCC goal, and it is likely to hit the IPCC 2040 goal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA Without Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "oil_rmse_cfg, oil_aic_cfg = arima_pdq_no_tran(\n",
    "                                        model_data.iloc[:,2:3], 22, 50, s=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deleteme\n",
    "stored_oil = selected_models.copy()\n",
    "selected_models = stored_oil.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "selected_models = stored_oil.copy()\n",
    "df_oil = model_data_t.iloc[:,4:6]\n",
    "\n",
    "#                        Model,       df_o,  pdq,    tran,            n,PDQs\n",
    "selected_models.append(['ARIMA_tran', df_oil,(1,0,1),'inv_difference',0,None])\n",
    "\n",
    "m = 2\n",
    "model_summary(selected_models[m][1], selected_models[m][2], 22, 50, 14,\n",
    "              selected_models[m][3], selected_models[m][4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's clear these oil plants will be shut down soon. I think this graph is reasonable. It's also consistent. If I have no d term, these graphs largly look the same no matter the p or q."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nuclear\n",
    "### Distribution Investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stored_model_data = model_data.copy()\n",
    "stored_model_data_t = model_data_t.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = stored_model_data.copy()\n",
    "model_data_t = stored_model_data_t.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hist(model_data.iloc[:,3:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_block = s_block(model_data.iloc[:,3:4], stats_block)\n",
    "stats_block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has a slightly negative skew distribution with wide and flat tails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposing The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomp_graph(model_data.iloc[:,3:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No seasonality or residuals. I'll check for stationarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for Stationarity and Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 30)\n",
    "stationarity_check(model_data.iloc[:,3:4], s=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not closer to stationary than the other graphs I've looked at. After playing around with transformations, I found that if I subtracted the rolling average of eight values, I can get it stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stored = model_data_t.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_data_t = stored.copy()\n",
    "t = subtract_roll_mean(model_data.iloc[:,3:4], n=8)\n",
    "model_data_t.insert(7,t.columns[0],t)\n",
    "\n",
    "model_data_t.iloc[:,6:8].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before I move forward, I want to make sure I can transform this data back after modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test = model_data_t.iloc[:,6:8].copy()\n",
    "\n",
    "test['Results'] = inv_subtract_roll_mean(test, n=8)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transferring back is a possibility. Therefore, I can move forward. I'll again check for stationarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stationarity_check(model_data_t.iloc[:,7:8], s=39)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My p-value is less than .05. Stationarity achieved. I'll look at the decomposition graph again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "decomp_graph(model_data_t.iloc[:,7:8].dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like there's still a trend line, but it does pass stationarity, so I'm moving forward to the baseline random walk model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Walk Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows',None)\n",
    "y_hat_proj = random_walk(model_data_t.iloc[:,7:8])\n",
    "y_hat_proj.columns = [model_data.columns[3]+' -Random Walk Model']\n",
    "\n",
    "# Plot the transformed Random Walk\n",
    "pred_graph(model_data_t.iloc[:,7:8], y_hat_proj.iloc[:,0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the DataFrame for Back Transformation\n",
    "ranplot = model_data_t.iloc[:,6:8].copy()\n",
    "ranplot.rename(columns={str(ranplot.columns[1]): str(y_hat_proj.columns[0])},\n",
    "               inplace=True)\n",
    "\n",
    "ranplot = pd.concat([ranplot,y_hat_proj],axis=0)\n",
    "\n",
    "# Perform Back Transformation\n",
    "y_hat_proj = inv_subtract_roll_mean(ranplot, n=8)\n",
    "\n",
    "#Plot the new graph\n",
    "pred_graph(model_data_t.iloc[:,6:7], y_hat_proj.iloc[22:,0:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is as unreliable as it's name would imply, random walk. Again, of the transformed data oscillates about the zero x-axis, then the model is going to unrealistic when transformed back.\n",
    "\n",
    "Now I'll move forward with an ARMA model. First, I need to evaluate the ACF and PACF plots to find the best Autoregressive and Moving Average terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Initial AR and MA Values with ACF and PACF Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotacf(model_data_t.iloc[:,7:8], lags = 6)\n",
    "plotpacf(model_data_t.iloc[:,7:8], lags = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neither ACF or PACF breaches at all. PACF gets close at 4 and 6. I'll try (1,0,0), (4,0,0), and (6,0,0) for my initial ARMA models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARMA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "order = (1,0,0)\n",
    "model_summary(model_data_t.iloc[:,6:8], order, 22, 50, 14,\n",
    "          tran = 'inv_subtract_roll_mean', n=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#order = (0,0,4)\n",
    "# model_summary(model_data_t.iloc[:,6:8], order, 22, 50, 0,\n",
    "#         tran = 'inv_subtract_roll_mean', n=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The combination above creates an error state. Sometimes this happens. All I can do is try a different model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "order = (1,0,6)\n",
    "model_summary(model_data_t.iloc[:,6:8], order, 22, 50, 0,\n",
    "          tran = 'inv_subtract_roll_mean', n=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I cannot explain why the two models diverge one spot earlier than I expected. Otherwise, both of these models look convincing. They show a steady incline in Nuclear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA Model and Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oil_rmse_cfg, oil_aic_cfg = arima_pdq(\n",
    "            model_data_t.iloc[:,6:8], s=14, tran='inv_subtract_roll_mean', n=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is reasonable, but it looks as though it added a bit of seasonality, which is curious. More research needs to be done into why nuclear tanked in 2012 and 2020/2021. It likely has something to do with the fact that nuclear is the most expensive kind of power generation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA Without Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "oil_rmse_cfg, oil_aic_cfg = arima_pdq_no_tran(\n",
    "                                        model_data.iloc[:,3:4], 22, 50, s=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deleteme\n",
    "stored_nuc = selected_models.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "selected_models = stored_nuc.copy() #deleteme\n",
    "df_nuclear = model_data_t.iloc[:,6:8]\n",
    "\n",
    "#                        Model,       df_o,       pdq,\n",
    "selected_models.append(['ARIMA_tran', df_nuclear, (8,1,7), \n",
    "                        'inv_subtract_roll_mean', 8, None])\n",
    "\n",
    "m = 3\n",
    "model_summary(selected_models[m][1], selected_models[m][2], 22, 50, 14,\n",
    "              selected_models[m][3], selected_models[m][4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model has the best RMSE and is reasonable. Though I don't think nuclear has such a set seasonal component, projects are that it will rise in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hydro\n",
    "### Distribution Investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stored_model_data = model_data.copy()\n",
    "stored_model_data_t = model_data_t.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = stored_model_data.copy()\n",
    "model_data_t = stored_model_data_t.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hist(model_data.iloc[:,4:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_block = s_block(model_data.iloc[:,4:5], stats_block)\n",
    "stats_block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is very close to normal distribution, with taller middle and thinner tails. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposing The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomp_graph(model_data.iloc[:,4:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No seasonality or residuals. I'll check for stationarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for Stationarity and Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 30)\n",
    "stationarity_check(model_data.iloc[:,4:5], s=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is close to stationary. After playing around with transformations, I found that if I subtracted the rolling average of four values, I can get it stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stored = model_data_t.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_data_t = stored.copy()\n",
    "t = subtract_roll_mean((model_data.iloc[:,4:5]), n=4)\n",
    "model_data_t.insert(9,t.columns[0],t)\n",
    "\n",
    "model_data_t.iloc[:,8:10].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before I move forward, I want to make sure I can transform this data back after modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test = model_data_t.iloc[:,8:10].copy()\n",
    "\n",
    "test['Results'] = inv_subtract_roll_mean(test, n=4)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transferring back is a possibility. Therefore, I can move forward. I'll again check for stationarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stationarity_check(model_data_t.iloc[:,9:10], s=39)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My p-value is less than .05. Stationarity achieved. I'll look at the decomposition graph again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "decomp_graph(model_data_t.iloc[:,9:10].dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like there's still a trend line, but it does pass stationarity, so I'm moving forward to the baseline random walk model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Walk Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows',None)\n",
    "y_hat_proj = random_walk(model_data_t.iloc[:,9:10])\n",
    "y_hat_proj.columns = [model_data.columns[4]+' -Random Walk Model']\n",
    "\n",
    "# Plot the transformed Random Walk\n",
    "pred_graph(model_data_t.iloc[:,9:10], y_hat_proj.iloc[:,0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the DataFrame for Back Transformation\n",
    "ranplot = model_data_t.iloc[:,8:10].copy()\n",
    "ranplot.rename(columns={str(ranplot.columns[1]): str(y_hat_proj.columns[0])},\n",
    "               inplace=True)\n",
    "\n",
    "ranplot = pd.concat([ranplot,y_hat_proj],axis=0)\n",
    "\n",
    "# Perform Back Transformation\n",
    "y_hat_proj = inv_subtract_roll_mean(ranplot, n=4)\n",
    "\n",
    "#Plot the new graph\n",
    "pred_graph(model_data_t.iloc[:,8:9], y_hat_proj.iloc[22:,0:1], 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is as unreliable as it's name would imply, random walk. A recurring theme is that if the transformed data is along the zero x-axis, random walk will simply not work.\n",
    "\n",
    "Now I'll move forward with an ARMA model. First, I need to evaluate the ACF and PACF plots to find the best Autoregressive and Moving Average terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Initial AR and MA Values with ACF and PACF Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotacf(model_data_t.iloc[:,9:10], lags = 6)\n",
    "plotpacf(model_data_t.iloc[:,9:10], lags = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ACF nearly breaches at 4, and PACF definitely breaches at 4. I will try both (4,0,0) and (4,0,4) for my ARMA model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARMA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "order = (4,0,0)\n",
    "model_summary(model_data_t.iloc[:,8:10], order, 22, 50, 14,\n",
    "          tran = 'inv_subtract_roll_mean', n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "order = (4,0,4)\n",
    "model_summary(model_data_t.iloc[:,8:10], order, 22, 50, 14,\n",
    "          tran = 'inv_subtract_roll_mean', n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both of these models look reasonable. In reality, we won't see much change in Hydro, just a change in how much the rivers flow. No further infrastructure is really possible in the United States."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA Model and Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "oil_rmse_cfg, oil_aic_cfg = arima_pdq(\n",
    "        model_data_t.iloc[:,8:10], s=14, tran='inv_subtract_roll_mean', n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I plotted the best RMSE, and it was a flat line. Neither graph is convincing. I'll have to try using one of the ARMA models above or an non-transformation model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA Without Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "oil_rmse_cfg, oil_aic_cfg = arima_pdq_no_tran(\n",
    "                                        model_data.iloc[:,4:5], 22, 50, s=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deleteme\n",
    "stored_hyd = selected_models.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "selected_models = stored_hyd.copy() #deleteme\n",
    "df_hydro = model_data_t.iloc[:,8:10]\n",
    "\n",
    "#                        Model,       df_o,     pdq\n",
    "selected_models.append(['ARIMA_tran', df_hydro, (4,0,4), \n",
    "                        'inv_subtract_roll_mean', 4, None])\n",
    "\n",
    "m = 4\n",
    "model_summary(selected_models[m][1], selected_models[m][2], 22, 50, 14,\n",
    "              selected_models[m][3], selected_models[m][4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to use (4,0,4) because it retains the seasonal element to hydro power. Hydro is dependent on the rain, and rain is not as reliable as the wind or sun. In dryer years, there is less rain. Also, this graph's RMSE, 35.06, is not dramatically different than the best RMSE with transformation, 19.34.\n",
    "\n",
    "That being said, there is not a lot of growth available to hydro, because we simply don't want to build more dams, which create their own environmental problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bioenergy\n",
    "### Distribution Investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stored_model_data = model_data.copy()\n",
    "stored_model_data_t = model_data_t.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = stored_model_data.copy()\n",
    "model_data_t = stored_model_data_t.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hist(model_data.iloc[:,5:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_block = s_block(model_data.iloc[:,5:6], stats_block)\n",
    "stats_block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is very close to normal distribution, with a slightly positive skew. It has wide, flat, tails. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposing The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomp_graph(model_data.iloc[:,5:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No seasonality or residuals. I'll check for stationarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for Stationarity and Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 30)\n",
    "stationarity_check(model_data.iloc[:,5:6], s=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not close to stationary. After playing around with transformations, I found that if I took the log and then subtracted the rolling average of nine values, I can get it stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stored = model_data_t.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_data_t = stored.copy()\n",
    "t = subtract_roll_mean(log_transform(model_data.iloc[:,5:6]), n=9)\n",
    "model_data_t.insert(11,t.columns[0],t)\n",
    "\n",
    "model_data_t.iloc[:,10:12].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before I move forward, I want to make sure I can transform this data back after modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test = model_data_t.iloc[:,10:12].copy()\n",
    "\n",
    "test['Results'] = inv_log_inv_sub(test, n=9)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transferring back is a possibility. Therefore, I can move forward. I'll again check for stationarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stationarity_check(model_data_t.iloc[:,11:12], s=54)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My p-value is less than .05. Stationarity achieved. I'll look at the decomposition graph again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "decomp_graph(model_data_t.iloc[:,11:12].dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like there's still a trend line, but it does pass stationarity, so I'm moving forward to the baseline random walk model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Walk Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows',None)\n",
    "y_hat_proj = random_walk(model_data_t.iloc[:,11:12])\n",
    "y_hat_proj.columns = [model_data.columns[5]+' -Random Walk Model']\n",
    "\n",
    "# Plot the transformed Random Walk\n",
    "pred_graph(model_data_t.iloc[:,11:12], y_hat_proj.iloc[:,0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the DataFrame for Back Transformation\n",
    "ranplot = model_data_t.iloc[:,10:12].copy()\n",
    "ranplot.rename(columns={str(ranplot.columns[1]): str(y_hat_proj.columns[0])},\n",
    "               inplace=True)\n",
    "\n",
    "ranplot = pd.concat([ranplot,y_hat_proj],axis=0)\n",
    "\n",
    "# Perform Back Transformation\n",
    "y_hat_proj = inv_log_inv_sub(ranplot, n=9)\n",
    "\n",
    "#Plot the new graph\n",
    "pred_graph(model_data_t.iloc[:,10:11], y_hat_proj.iloc[22:,0:1], 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is as unreliable as it's name would imply, random walk. This one works ok because the standard deviation is incredibly small.\n",
    "\n",
    "Now I'll move forward with an ARMA model. First, I need to evaluate the ACF and PACF plots to find the best Autoregressive and Moving Average terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Initial AR and MA Values with ACF and PACF Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotacf(model_data_t.iloc[:,11:12], lags = 5)\n",
    "plotpacf(model_data_t.iloc[:,11:12], lags = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ACF and PACF both breach at 1. Also, PACF nearly breaches at 3. I'll try (1,0,1) and (3,0,1) for my initial ARMA models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARMA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "order = (1,0,1)\n",
    "model_summary(model_data_t.iloc[:,10:12], order, 22, 50, 14,\n",
    "          tran = 'inv_log_inv_sub', n=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "order = (3,0,1)\n",
    "model_summary(model_data_t.iloc[:,10:12], order, 22, 50, 0,\n",
    "          tran = 'inv_log_inv_sub', n=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first shows a slight decline, the second a slight incline. I'll have to see what Grid Search says."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA Model and Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bio_rmse_cfg, oil_aic_cfg = arima_pdq(\n",
    "            model_data_t.iloc[:,10:12], s=14, tran='inv_log_inv_sub', n=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bio energy is a dubious concept to begin with. It burns trees and replants with regularity, claiming that the new trees make it carbon neutral. Not only dubious, but egregious too. I will use the best RMSE graph for this, hoping for more of an overall decline rather than a rebound in the industry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA Without Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bio_rmse_cfg, oil_aic_cfg = arima_pdq_no_tran(\n",
    "                                        model_data.iloc[:,5:6], 22, 50, s=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deleteme\n",
    "stored_bio = selected_models.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "selected_models = stored_bio.copy() #deleteme\n",
    "df_bio = model_data_t.iloc[:,10:12]\n",
    "\n",
    "#                        Model,       df_o,  pdq,    tran,             n,PDQs\n",
    "selected_models.append(['ARIMA_tran', df_bio,(8,1,1),'inv_log_inv_sub',9,None])\n",
    "\n",
    "m = 5\n",
    "model_summary(selected_models[m][1], selected_models[m][2], 22, 50, 14,\n",
    "              selected_models[m][3], selected_models[m][4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the best RMSE, and I think it's reasonable to say a slight decline will happen in the next few years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wind\n",
    "### Distribution Investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stored_model_data = model_data.copy()\n",
    "stored_model_data_t = model_data_t.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = stored_model_data.copy()\n",
    "model_data_t = stored_model_data_t.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hist(model_data.iloc[:,6:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_block = s_block(model_data.iloc[:,6:7], stats_block)\n",
    "stats_block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has a positive skew with wide and flat tails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposing The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomp_graph(model_data.iloc[:,6:7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No seasonality or residuals. I'll check for stationarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for Stationarity and Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 30)\n",
    "stationarity_check(model_data.iloc[:,6:7], s=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first time, we have stationary data. There is no need for transforming at all. However, for the sake of keeping the transformation column consistent, I'll still create a copy of this data into the transformation DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stored = model_data_t.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_data_t = stored.copy()\n",
    "t = model_data.iloc[:,6:7]\n",
    "t.columns = ['Copy of ' + model_data.columns[6]]\n",
    "model_data_t.insert(13,t.columns[0],t)\n",
    "\n",
    "model_data_t.iloc[:,12:14].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Walk Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows',None)\n",
    "y_hat_proj = random_walk(model_data.iloc[:,6:7])\n",
    "y_hat_proj.columns = [model_data.columns[6]+' -Random Walk Model']\n",
    "\n",
    "# Plot the transformed Random Walk\n",
    "pred_graph(model_data.iloc[:,6:7], y_hat_proj.iloc[:,0:1], 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is as unreliable as it's name would imply, random walk. This one works better because there is no transformation.\n",
    "\n",
    "Now I'll move forward with an ARMA model. First, I need to evaluate the ACF and PACF plots to find the best Autoregressive and Moving Average terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Initial AR and MA Values with ACF and PACF Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotacf(model_data.iloc[:,6:7], lags = 8)\n",
    "plotpacf(model_data.iloc[:,6:7], lags = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ACF and PACF both breach at one. I'll try (1, 0, 1) for my first ARMA model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARMA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "order = (1,0,1)\n",
    "model_summary_no_tran(model_data.iloc[:,6:7], order, 22, 50, 14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, no and no. Wind is doing nothing but rising in the US. This graph should reflect that. I'll have to look at this through Grid Search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA Without Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bio_rmse_cfg, oil_aic_cfg = arima_pdq_no_tran(\n",
    "                                        model_data.iloc[:,6:7], 22, 50, s=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best RMSE looks decent, the best AIC is clearly wrong. Wind is on the rise, so here's to hoping it will continue to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deleteme\n",
    "stored_wind = selected_models.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "selected_models = stored_wind.copy() #deleteme\n",
    "df_wind = model_data_t.iloc[:,12:13]\n",
    "\n",
    "#                        Model,   df_o,   pdq,     tran, n, PDQs\n",
    "selected_models.append(['ARIMA', df_wind, (8,2,7), None, 0, None])\n",
    "\n",
    "m = 6\n",
    "model_summary_no_tran(selected_models[m][1], selected_models[m][2], 22, 50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is great. My only hope is that wind is really on an exponential curve upward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solar\n",
    "### Distribution Investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stored_model_data = model_data.copy()\n",
    "stored_model_data_t = model_data_t.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = stored_model_data.copy()\n",
    "model_data_t = stored_model_data_t.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hist(model_data.iloc[:,7:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_block = s_block(model_data.iloc[:,7:8], stats_block)\n",
    "stats_block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a very positively skewed distribution. It has thinner tails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposing The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomp_graph(model_data.iloc[:,7:8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No seasonality or residuals. I'll check for stationarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for Stationarity and Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 30)\n",
    "stationarity_check(model_data.iloc[:,7:8], s=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not close to stationary. After playing around with transformations, I found that if I took the log and then subtracted the rolling average of eight values, I can get it stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stored = model_data_t.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_data_t = stored.copy()\n",
    "t = subtract_roll_mean(log_transform(model_data.iloc[:,7:8]), n=8)\n",
    "model_data_t.insert(15,t.columns[0],t)\n",
    "\n",
    "model_data_t.iloc[:,14:16].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before I move forward, I want to make sure I can transform this data back after modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test = model_data_t.iloc[:,14:16].copy()\n",
    "\n",
    "test['Results'] = inv_log_inv_sub(test, n=8)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transferring back is a possibility. Therefore, I can move forward. I'll again check for stationarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stationarity_check(model_data_t.iloc[:,15:16], s=54)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My p-value is less than .05. Stationarity achieved. I'll look at the decomposition graph again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "decomp_graph(model_data_t.iloc[:,15:16].dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like there's still a trend line, but it does pass stationarity, so I'm moving forward to the baseline random walk model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Walk Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows',None)\n",
    "y_hat_proj = random_walk(model_data_t.iloc[:,15:16])\n",
    "y_hat_proj.columns = [model_data.columns[7]+' -Random Walk Model']\n",
    "\n",
    "# Plot the transformed Random Walk\n",
    "pred_graph(model_data_t.iloc[:,15:16], y_hat_proj.iloc[:,0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the DataFrame for Back Transformation\n",
    "ranplot = model_data_t.iloc[:,14:16].copy()\n",
    "ranplot.rename(columns={str(ranplot.columns[1]): str(y_hat_proj.columns[0])},\n",
    "               inplace=True)\n",
    "\n",
    "ranplot = pd.concat([ranplot,y_hat_proj],axis=0)\n",
    "\n",
    "# Perform Back Transformation\n",
    "y_hat_proj = inv_log_inv_sub(ranplot, n=8)\n",
    "\n",
    "#Plot the new graph\n",
    "pred_graph(model_data_t.iloc[:,14:15], y_hat_proj.iloc[22:,0:1], 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is as unreliable as it's name would imply, random walk. Oscillating about zero and a large standard deviation a bad random walk. This one doesn't disappoint.\n",
    "\n",
    "Now I'll move forward with an ARMA model. First, I need to evaluate the ACF and PACF plots to find the best Autoregressive and Moving Average terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Initial AR and MA Values with ACF and PACF Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotacf(model_data_t.iloc[:,15:16], lags = 6)\n",
    "plotpacf(model_data_t.iloc[:,15:16], lags = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both ACF and PACF breach at 1. I'll try (1, 0, 1) for the first ARMA model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARMA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows',60)\n",
    "order = (1,0,1)\n",
    "model_summary(model_data_t.iloc[:,14:16], order, 22, 50, 14,\n",
    "          tran = 'inv_log_inv_sub', n=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solar is growing very but to product nearly thirty times the electricity needs of the united states would mean the entire surface of the planet would be one giant solar panel. No, not really, but this doesn't make sense regardless."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA Model and Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gas_rmse_cfg, gas_aic_cfg = arima_pdq(\n",
    "                model_data_t.iloc[:,14:16], s=14, tran = 'inv_log_inv_sub', n=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm glad that solar is on the rise, but it's doubtful that the United States will have enough solar energy to power the electricity needs of earth several times over by 2050. I'll see what the graph without transformations says."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA Without Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gas_rmse_cfg, gas_aic_cfg = arima_pdq_no_tran(\n",
    "                                        model_data.iloc[:,7:8], 22, 50, s=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deleteme\n",
    "stored_solar = selected_models.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "selected_models = stored_solar.copy() #deleteme\n",
    "df_solar = model_data_t.iloc[:,14:15]\n",
    "\n",
    "#                        Model,   df_o,    pdq,     tran, n, PDQs\n",
    "selected_models.append(['ARIMA', df_solar, (8,3,7), None, 0, None])\n",
    "\n",
    "m = 7\n",
    "model_summary_no_tran(selected_models[m][1], selected_models[m][2], 22, 50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Order (8,3,8) seemed to be an outlier. Most of the solar curves guessed the level of TWh for solar by 2050 around 2500 TWh. (8,3,8) was the only one that pushed that number past 2600 that had a good RMSE, and to do it by a whole thousand? That seems wishful. Also, the RMSE between the best RMSE (8,3,8) and the second best (8,3,7) was less than a hundredth decimal place. \n",
    "\n",
    "This one did not rely on transformations. All the graphs with transformation gave unreasonable high estimates, like solar had several times the power needs of the entire earth's economy by 2050. I'm happy with this graph as it is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Renewables\n",
    "### Distribution Investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist(model_data.iloc[:,8:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_block = s_block(model_data.iloc[:,8:9], stats_block)\n",
    "stats_block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data is negatively skewed, but also the kurtosis is closest to zero, so it closely resembles standard deviation other than the negative skew."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposing The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomp_graph(model_data.iloc[:,8:9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No seasonality or residuals. I'll check for stationarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for Stationarity and Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 30)\n",
    "stationarity_check(model_data.iloc[:,8:9], s=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is close to stationary. After playing around with transformations, I found that if I took the plotted the difference and then subtracted the rolling average of six values, I can get it stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stored = model_data_t.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_data_t = stored.copy()\n",
    "t = subtract_roll_mean(difference(model_data.iloc[:,8:9]), n=6)\n",
    "model_data_t.insert(17,t.columns[0],t)\n",
    "\n",
    "model_data_t.iloc[:,17:18]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before I move forward, I want to make sure I can transform this data back after modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test = model_data_t.iloc[:,16:18].copy()\n",
    "test.iloc[:,1:2] = inv_diff_inv_sub(test,n=6)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transferring back is a possibility. Therefore, we can move forward. I'll again check for stationarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stationarity_check(model_data_t.iloc[:,17:18], s=56)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My p-value is less than .05. Stationarity achieved. I'll look at the decomposition graph again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "decomp_graph(model_data_t.iloc[:,17:18].dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like there's still a trend line, but it does pass stationarity, so I'm moving forward to the baseline random walk model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Walk Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows',None)\n",
    "y_hat_proj = random_walk(model_data_t.iloc[:,17:18])\n",
    "y_hat_proj.columns = [model_data.columns[8]+' -Random Walk Model']\n",
    "\n",
    "# Plot the transformed Random Walk\n",
    "pred_graph(model_data_t.iloc[:,17:18], y_hat_proj.iloc[:,0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Prepare the DataFrame for Back Transformation\n",
    "ranplot = model_data_t.iloc[:,16:18].copy()\n",
    "ranplot.rename(columns={str(ranplot.columns[1]): str(y_hat_proj.columns[0])},\n",
    "               inplace=True)\n",
    "ranplot = pd.concat([ranplot,y_hat_proj],axis=0)\n",
    "\n",
    "# Perform Back Transformation\n",
    "y_hat_proj = inv_diff_inv_sub(ranplot, n=6)\n",
    "\n",
    "#Plot the new graph\n",
    "pred_graph(model_data.iloc[:,8:9], y_hat_proj.iloc[22:,0:1], 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is as unreliable as it's name would imply, random walk. This one does ok because of the low standard deviation.\n",
    "\n",
    "Now I'll move forward with an ARMA model. First, I need to evaluate the ACF and PACF plots to find the best Autoregressive and Moving Average terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Initial AR and MA Values with ACF and PACF Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotacf(model_data_t.iloc[:,17:18], lags = 6)\n",
    "plotpacf(model_data_t.iloc[:,17:18], lags = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No breaches at all. I'll try (1,0,0) for the first model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARMA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows',60)\n",
    "order = (1,0,0)\n",
    "model_summary(model_data_t.iloc[:,16:18], order, 22, 50, 14,\n",
    "          tran = 'inv_diff_inv_sub', n=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't think we'll see drop in non-wind/solar renewables. I'll see what the Grid Search yields."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA Model and Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "coal_rmse_cfg, coal_aic_cfg = arima_pdq(\n",
    "                model_data_t.iloc[:,16:18], s=14, \n",
    "                    tran = 'inv_diff_inv_sub', n=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph may be more reasonable than it looks. I think it's strange that the RMSE values peaked before getting past a single digit increase for p, d, and q, but I double checked the numbers and it's right.\n",
    "\n",
    "The other renewables category represent new sources of energy that are GHG emission free. I think we will see a lot of growth in this market in the next three decades. In fact, at peaking out at 70 TWhs, it's possible this may be conservative. This is where fusion will go if it ever gets off the ground, after all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA Without Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "oth_rmse_cfg, oth_aic_cfg = arima_pdq_no_tran(model_data.iloc[:,8:9], 22, 50, s=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deleteme\n",
    "stored_other = selected_models.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "selected_models = stored_other.copy() #deleteme\n",
    "df_other = model_data_t.iloc[:,16:18]\n",
    "\n",
    "#                        Model,       df_o,     pdq,\n",
    "selected_models.append(['ARIMA_tran', df_other, (1,1,0),\n",
    "                        'inv_diff_inv_sub', 6, None])\n",
    "\n",
    "m = 8\n",
    "#model_summary_no_tran(selected_models[m][1], selected_models[m][2], 22, 50);\n",
    "# model_summary(df, o, st, en, s=0, tran=None, n=0):\n",
    "model_summary(selected_models[m][1], selected_models[m][2], 22, 50, 14,\n",
    "              selected_models[m][3], selected_models[m][4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I wrote above, an exponential curve might be fight for other renewable sources of energy. This is research and there is a lot of money going into this market. It might even be conservative. This curve has the best RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphing Energy Production Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_hats_sel_mod(sel_mod, st, en):\n",
    "    y_hats = pd.DataFrame()\n",
    "    for sm in sel_mod:\n",
    "        if sm[0] == 'ARIMA':\n",
    "            m, y_hat, yo = arima_no_tran(\n",
    "                                sm[1], sm[2], st, en)\n",
    "\n",
    "        elif sm[0] == 'ARIMA_tran':\n",
    "            yt, df, y_hat = mod_pred_s(sm[1], sm[2], st, en, tran=sm[3],\n",
    "                                      n=sm[4])\n",
    "                \n",
    "            # Setting the first point of y-hat to the last point of the \n",
    "            # DataFrame to show continuious change on the graph.\n",
    "            y_hat.loc[sm[1].index[-1], y_hat.columns] = sm[1].iloc[-1,0].copy()\n",
    "            # Sorting index\n",
    "            y_hat.sort_index(inplace=True)\n",
    "        \n",
    "        # Adding the y_hat to the DataFrame with all y_hats\n",
    "        y_hats = pd.concat([y_hats,y_hat], axis=1)\n",
    "    \n",
    "    # Setting all negative y-hat values to zero.\n",
    "    y_hats[y_hats < 0] = 0\n",
    "    \n",
    "    return y_hats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacked_energy_proj(his_en, his_dem, pj_en, pj_dem, title, s=0):\n",
    "\n",
    "    df_names = list(pj_en.columns.copy())\n",
    "    if s>0:\n",
    "        for i in range(len(df_names)):\n",
    "            # In case the beginning of the column is \"Back Transformation of \"\n",
    "            # but the graph doesn't need that in the index label.\n",
    "            if df_names[i][:23] == 'Back Transformation of ':\n",
    "                ss = s+23\n",
    "            else:\n",
    "                ss = s+0\n",
    "            df_names[i] = str(df_names[i])[ss:]\n",
    "    \n",
    "    his_dem.name = his_dem.iloc[:,0:1].columns[0][s:]\n",
    "    pj_dem.name = pj_dem.iloc[:,0:1].columns[0][s:]\n",
    "\n",
    "    fig = plt.figure(figsize = (20,12))\n",
    "    plt.title(title, size = 15)\n",
    "\n",
    "    # Plotting the demand\n",
    "    plt.plot(his_dem.index, his_dem.iloc[:,0], '--', \n",
    "             label = his_dem.name)\n",
    "    plt.plot(pj_dem.index, pj_dem.iloc[:,0], '--', color = 'red',\n",
    "             label = pj_dem.name)\n",
    "    \n",
    "    his_en_lst = []\n",
    "    for i in range(len(his_en.columns)):\n",
    "        his_en_lst.append(his_en.iloc[:,i])\n",
    "        \n",
    "    pj_en_lst = []\n",
    "    for i in range(len(pj_en.columns)):\n",
    "        pj_en_lst.append(pj_en.iloc[:,i])\n",
    "    \n",
    "    # Printing the stacked energy production\n",
    "    # Resetting colors to ensure color parity across predicted and historic.\n",
    "    plt.gca().set_prop_cycle(None)\n",
    "    plt.stackplot(his_en.index, his_en_lst)\n",
    "    # Resetting colors to ensure color parity across predicted and historic.\n",
    "    plt.gca().set_prop_cycle(None)\n",
    "    plt.stackplot(pj_en.index, pj_en_lst, labels = df_names)\n",
    "    \n",
    "    # Line at x-axis showing historic vs projected\n",
    "    plt.axvline(his_en.index[-1], color = 'black', linestyle = 'dashed',\n",
    "                label = 'Historic / Projected')\n",
    "    \n",
    "    # Formatting\n",
    "    plt.xlabel('Year', size = 15)\n",
    "    plt.ylabel('TWh', size = 15)\n",
    "    plt.xticks(size=15)\n",
    "    plt.yticks(size=15)\n",
    "    plt.legend(loc=2)\n",
    "    # show the graph\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_hats = y_hats_sel_mod(selected_models, 22, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line at x-axis showing historic vs projected\n",
    "plt.axvline(df_hist_dem.index[-1], color = 'black', linestyle = 'dashed',\n",
    "                label = 'Historic / Projected')\n",
    "\n",
    "line8 =  model_data.iloc[:,8].plot(label = 'Other Renewable')\n",
    "line7 =  model_data.iloc[:,7].plot(label = 'Solar')\n",
    "line6 =  model_data.iloc[:,6].plot(label = 'Wind')\n",
    "line5 =  model_data.iloc[:,5].plot(label = 'Bioenergy')\n",
    "line4 =  model_data.iloc[:,4].plot(label = 'Hydro')\n",
    "line3 =  model_data.iloc[:,3].plot(label = 'Nuclear')\n",
    "line2 =  model_data.iloc[:,2].plot(label = 'Oil')\n",
    "line1 =  model_data.iloc[:,1].plot(label = 'Gas')\n",
    "line0 =  model_data.iloc[:,0].plot(figsize=(15,4),label = 'Coal')\n",
    "\n",
    "plt.legend(loc = 6)\n",
    "\n",
    "# Resetting colors to ensure color parity across predicted and historic.\n",
    "plt.gca().set_prop_cycle(None)\n",
    "\n",
    "line8_pred = y_hats.iloc[:,8].plot()\n",
    "line7_pred = y_hats.iloc[:,7].plot()\n",
    "line6_pred = y_hats.iloc[:,6].plot()\n",
    "line5_pred = y_hats.iloc[:,5].plot()\n",
    "line4_pred = y_hats.iloc[:,4].plot()\n",
    "line3_pred = y_hats.iloc[:,3].plot()\n",
    "line2_pred = y_hats.iloc[:,2].plot()\n",
    "line1_pred = y_hats.iloc[:,1].plot()\n",
    "line0_pred = y_hats.iloc[:,0].plot()\n",
    "\n",
    "\n",
    "plt.title('USA Historical Power Generation Methods (TWh) 2000–2021');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Energy use projected into the future.\n",
    "stacked_energy_proj(model_data.iloc[:,::-1], df_hist_dem.iloc[:,8:9],\n",
    "                    y_hats.iloc[:,::-1], df_proj_dem_stat.iloc[:,8:9], \n",
    "                'United States Energy Production\\nHistoric and Projected', 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph shows the projected energy production until the year 2050. To meet the Paris Agreement, we have to diminish coal, oil and natural gas. As the graph shows, coal is already on a trend out, as is oil. Natural gas will be difficult to trim as its rise will make up nearly half of all energy production by 2050. That's my task in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduction in Natural Gas Energy Production to Meet Paris Agreement Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame for the reduction of natural gas, and increase of\n",
    "# renewables.\n",
    "pd.set_option('display.max_rows',6)\n",
    "\n",
    "rdc_y_hats = y_hats.copy()\n",
    "rdc_y_hats.columns = model_data.columns\n",
    "df_pts = rdc_y_hats.copy()\n",
    "rdc_y_hats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuclear plants take a long, long time to build. For example, Wyoming has a Nuclear power plant under construction now that is scheduled to open in 2030. To meet the 2030 target, we need to deploy renewable energy production at a much faster rate. The only way to do this is to expand wind and solar technology.\n",
    "\n",
    "At current construction rates, it will be difficult to replace the reduction we need in natural gas with wind and solar. Instead, I'll say we continue natural gas production for three years, then start the rapid reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the natural gas column ready for interpolation, starting with three\n",
    "# years into the projected values.\n",
    "rdc_y_hats.iloc[4:,1] = np.nan\n",
    "\n",
    "rdc_y_hats.rename(columns = {rdc_y_hats.columns[1] : \n",
    "                             rdc_y_hats.columns[1] + ' -Targets'},\n",
    "                              inplace=True)\n",
    "rdc_y_hats.iloc[:,1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the 2030 reduction target number for gas. We need to be at 45% \n",
    "# of 2010's production level.\n",
    "display(model_data.iloc[10:11,1:2])\n",
    "gas_2030_target = model_data.iloc[10,1]*.45\n",
    "print('The IPCC target for gas is 45% of the 2010 production levels.',\n",
    "      '\\nForty five percent of {:.2f} TWh is {:.2f} TWh.'.format(\n",
    "          model_data.iloc[10,1], gas_2030_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "# Setting gas targets for 2030 and 2050\n",
    "# 2030 is row 9.\n",
    "rdc_y_hats.iloc[9,1] = gas_2030_target\n",
    "rdc_y_hats.iloc[-1,1] = 0\n",
    "\n",
    "# Interpolate the remaining values.\n",
    "rdc_y_hats.interpolate('linear', inplace=True)\n",
    "display(rdc_y_hats.iloc[:,1:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll reprint the slide with the natural gas reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Printing the future energy projections again.\n",
    "stacked_energy_proj(model_data.iloc[:,::-1], df_hist_dem.iloc[:,8:9],\n",
    "                    rdc_y_hats.iloc[:,::-1], df_proj_dem_stat.iloc[:,8:9], \n",
    "                ('United States Energy Production\\n' + \n",
    "                 \"Achieving the IPCC's targets to the Paris Agreement\"), 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a lot of energy that the United States needs to make up for. The first thing I need to do is calculate the 2030 deficit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell calculates the necessary numbers and explains what they mean.\n",
    "\n",
    "energy_produced_2030 = np.sum(rdc_y_hats.iloc[9,:])\n",
    "energy_demand_2030 = df_proj_dem_stat.iloc[1,8]\n",
    "energy_deficit_2030 = energy_demand_2030 - energy_produced_2030\n",
    "\n",
    "print('IEA Projected Energy Demand USA 2030: ',\n",
    "      '{:.2f} KWh'.format(energy_demand_2030))\n",
    "print('Production with natural gas reduction:',\n",
    "      '{:.2f} KWh'.format(energy_produced_2030))\n",
    "print('Deficit of energy production:         ',\n",
    "      '{:.2f} KWh\\n'.format(energy_deficit_2030))\n",
    "\n",
    "print('In the year 2030, the IEA projects that United States will ' +\n",
    "      'need {:.2f} KWh of'.format(energy_demand_2030),\n",
    "      '\\nenergy. If, by then, the United States has reduced Natural Gas', \n",
    "      'emissions to',\n",
    "      '\\nIPCC recommended levels, then the United States will have an energy',\n",
    "      'deficit\\nof {:.2f} KWh.'.format(energy_deficit_2030),\n",
    "      'The best chance the United States has to making up this deficit',\n",
    "      '\\nis to construct more wind and solar power.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculating the annual increase for wind and solar power.\n",
    "diffs = rdc_y_hats.iloc[:,6:8].diff()\n",
    "# I will set the rate of change of the first year as the initial production\n",
    "# rate.\n",
    "prod_rate = diffs.iloc[1]\n",
    "\n",
    "# Double capacity of wind and solar production annually for three years.\n",
    "for i in range(1,4):\n",
    "    prod_rate = prod_rate*2\n",
    "    rdc_y_hats.iloc[i:i+2,6:8] = rdc_y_hats.iloc[i-1,6:8] + prod_rate\n",
    "    \n",
    "# Keep that production rate steady perpetually.\n",
    "for i in range(4,len(rdc_y_hats)):\n",
    "    rdc_y_hats.iloc[i:i+1,6:8] = rdc_y_hats.iloc[i-1:i,6:8] + prod_rate\n",
    "\n",
    "print('Proposed annual production rate of wind and solar:')\n",
    "display(prod_rate)\n",
    "    \n",
    "rdc_y_hats.iloc[:,6:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I'll plot how these changes will affect the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Energy use projected into the future.\n",
    "stacked_energy_proj(model_data.iloc[:,::-1], df_hist_dem.iloc[:,8:9],\n",
    "                    rdc_y_hats.iloc[:,::-1], df_proj_dem_stat.iloc[:,8:9], \n",
    "                ('United States Energy Production\\n' + \n",
    "                 \"Achieving the IPCC's targets to the Paris Agreement\"), 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That achieves the objectives set out by the IPCC to meet Paris Agreement commitments. Natural gas use is down in to the required levels. Oil, and nearly coal, both are diminished entirely by 2030, and renewable production is powering the United States. The good news is the massive surplus the United States has made for itself can be exported to other nations in need of clean power themselves. This is, after all, a global problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations of Scope / Provided Data\n",
    "\n",
    "This analysis is limited to just the United States, and also doesn't clarify how the reduction in natural gas production will affect the earth's temperature at all. I have data available that will allow me to:\n",
    "\n",
    "1. **Add All Nations:** Project the energy generation of other nations of the world, and perform a similar analysis for how they can reduce their reliance on fossil fuels.\n",
    "\n",
    "\n",
    "2. **Estimate Proposed GHG Emissions Reductions:** Convert the power generation sources into estimates on GHG emissions. I have equations available that can accomplish this.\n",
    "\n",
    "\n",
    "3. **Combine This Analysis With the SSP Scenarios:** Compare how reductions across the world will reduce projected GHG emissions through the different Shared Socioeconomic Pathway (SSP) scenarios proposed by the IPCC. The SSPs are used to measure what global temperatures will be like under different circumstances. I have emissions data available for each. I can subtract my emission reductions from each to see how that will effect the overall picture of each SSP.\n",
    "\n",
    "\n",
    "4. **Correlate Emissions with Atmospheric Concentration:** Create time series analysis that correlate CO2 and CH4 emissions into the atmospheric concentration of both substances. The emissions data will be from the SSP scenarios as specified above. If I can correlate that with atmospheric concentration, then I can...\n",
    "\n",
    "\n",
    "5. **Determine Radiative Forcings:** Convert the CO2 and CH4 atmospheric concentrations into radiative forcing with a calculation provided by NOAA and the IPCC. Radiative forcings are the common unit that allows scientists to analyze different chemical's heat absorption from the sun, which has lead to this global crisis.\n",
    "\n",
    "\n",
    "6. **Global Annual Average Temperature** Convert the radiative forcing into estimated average annual temperature change.\n",
    "\n",
    "In short, these steps will allow me to measure how the change in electricity production fuel sources will correlate with the change in average annual temperature for the world. This is my dream scope for this project. I've gathered all the data already. The only missing factor is time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Research Opportunities\n",
    "\n",
    "* **Enact the Dream Scope:** I would like to analyze all the countries and regions of the world in the same way I did the United States. I would like to connect the dots to draw a direct correlation between power generation sources and the average annual global temperature.\n",
    "\n",
    "\n",
    "* **Add 2022's Data:** I would also like to add 2022's electricity generation data so I don't have to begin projecting after 2021.\n",
    "\n",
    "\n",
    "* **Better Emissions Data:** Though I didn't use it for this analysis, as part of the dream scope, I found emissions data on all countries, but it had one frustrating omission. I couldn't find emissions data exclusively for the power generation sector. The data I could find on this issue combined emissions from power generation with emissions from all fuel combustion, including automobiles. I would like to further research this so I could better learn the scope of emissions for the power generation sector.\n",
    "\n",
    "\n",
    "* **Primary Power:** This analysis focused exclusively on Secondary Power, which is making the fuel at the power plant. It doesn't acknowledge emissions from extracting natural gas, oil and coal from the earth. We know that a lot of carbon emissions occurs before the primary fuel source enters the power plant ready to be burned. It would be interesting to see how much reducing reliance on these fuel sources decreases emissions at their extraction.\n",
    "\n",
    "\n",
    "* **Transmission Losses:** Energy is loss between power plants and the businesses and homes they service just through the transmission across the power lines. It would be interesting to add these considerations to the study.\n",
    "\n",
    "\n",
    "* **Atmospheric Concentration of Methane (CH4):** Before I limited my scope to America and power generation reduction to meet IPCC targets, I experimented with building a time series model to correlate GHG emissions with atmospheric concentration. I successfully modeled the atmospheric concentrations with CO2 emissions, but I could not correlate Methane emissions with atmospheric concentration. This will take more research. (To view this work, look at the Multivariate Jupyter Notebook found in the same directory as this notebook.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations\n",
    "\n",
    "This analysis yields to three recommendations:\n",
    "\n",
    "1. **Reduce Natural Gas:** We are fortunate that market forces are driving coal and oil power production out of existence. The same is not true for natural gas. It is already the primary source of electricity generation in America. We must actively prepare for its replacement as soon as possible.\n",
    "\n",
    "\n",
    "2. **Double Production of Wind and Solar Power:** This is critical. To meet the future challenges of reducing our GHG emissions in the power generation sector, we must replace it with renewable energy that does not emit GHG at all. At this time, the United States is not producing enough new wind turbines and solar panels to account for the reductions we need. We must double capacity, the double capacity, then double capacity a third time for the next three years. Then we will have the production capacity to eliminate natural gas power generation.\n",
    "\n",
    "\n",
    "3. **Export Wind and Solar:** If we ramp up our solar and wind capabilities to meet the challenge we face, there will be no reason to cease operating at this capacity. Sell the excess solar panels and wind turbines to other nations. This will be good business for the United States, and it will help meet the challenges we face with the climate crisis. Acting alone will not be enough to preserve the world we live in today. We must do everything we can to encourage other nations to switch to renewable energy sources as soon as possible.\n",
    "\n",
    "\n",
    "Here are three more recommendations that are not detailed by this analysis, but are related to the problem:\n",
    "1. **Invest in Nuclear ASAP:** I did not consider new nuclear power plants as a replacement for natural gas for two reasons: 1) Nuclear is the most expensive fuel source at this time and 2) Nuclear plants take about a decade to build. \n",
    "\n",
    "    However, there are multiple companies rapidly trying to change this, or as rapidly as they can. [TerraPower](https://www.terrapower.com/), owned by Bill Gates, is currently building a power plant in Wyoming, but it doesn't open until 2030. Even then, the amount of electricity it will provide is not enough to significantly replace natural gas. It is a test project to see if Nuclear Power can be done safer and cheaper. If it works, it theoretically could be mass produced across the country, and the world, but... now we're talking about 2040 at the earliest. We need solutions between now and then. Those solutions are the use of wind and solar. It's the best we've got at this time.\n",
    "    \n",
    "\n",
    "2. **Invest in Educating the Public:** Years ago, the United States forced cigarette manufacturers to spend as much money on raising awareness of the ill effects of smoking as they did on advertising. It was very effective. Americans do not smoke as much as many other countries. Why not do the same thing with the dangers of fossil fuels? Part of the reason the climate crisis has been so difficult to manage politically is the public is barely aware of the dangers or the exact causes. Help the public understand the effects of emissions, including the eight million people who die every year of pollution born diseases.\n",
    "\n",
    "\n",
    "3. **Buy Natural Gas Power Companies:** American capitalists will fight he reduction in natural gas as hard as they possibly can because it is their paycheck. Instead of the government playing the role of regulator and legislating natural gas out of existence, take a page from the time-honored tradition of buying them out. Answer the cries of communism with a promise to sell the companies back to some willing capitalist a specified number of years after their emissions have dropped to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a wrap! Thanks for hiring Greg Osborne and I hope to work with you more in the future."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Project 5 – What would it take to Meet the Paris Agreement Energy Production Targets?",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "392.8px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
